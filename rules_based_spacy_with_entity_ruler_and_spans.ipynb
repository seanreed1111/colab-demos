{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/seanreed1111/colab-demos/blob/master/rules_based_spacy_with_entity_ruler_and_spans.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "- https://github.com/AnushaDeviR/nlp_spacy_basics/tree/main"
      ],
      "metadata": {
        "id": "8MlsXQ8qiqhU"
      },
      "id": "8MlsXQ8qiqhU"
    },
    {
      "cell_type": "markdown",
      "id": "a9e4ee81",
      "metadata": {
        "id": "a9e4ee81"
      },
      "source": [
        "# Rules-based Spacy"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "158f020c",
      "metadata": {
        "id": "158f020c"
      },
      "source": [
        "### Using SpaCy's EntityRuler\n",
        "\n",
        "- 2 different ways to add custom features to language-based pipelines:\n",
        "  1. rules-based\n",
        "  1. machine learning based approach\n",
        "  \n",
        "- Rule-based approach is taken when a set of rules can be generated using a list of known things or rules generated from regex or linguistic features (used to recoginize dates)\n",
        "- ML-based approach is taken when we don't know the rules or are complicated (used in entity recoginition of names)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "804fec72",
      "metadata": {
        "id": "804fec72"
      },
      "outputs": [],
      "source": [
        "import spacy"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "cjDB2pZ8io58"
      },
      "id": "cjDB2pZ8io58"
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "9a30e9f2",
      "metadata": {
        "id": "9a30e9f2"
      },
      "outputs": [],
      "source": [
        "nlp = spacy.load('en_core_web_sm')\n",
        "# our code should be able to extract `harry potter` as a movie and 'Azkaban' as a place\n",
        "text = 'Azkaban was referenced in Harry Potter.'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "0fcd6852",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0fcd6852",
        "outputId": "74892d2d-6183-4e98-9184-9681fe7bbb6b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Azkaban ORG\n",
            "Harry Potter PERSON\n"
          ]
        }
      ],
      "source": [
        "doc = nlp(text)\n",
        "for ent in doc.ents:\n",
        "    print(ent.text, ent.label_)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "id": "ea923718",
      "metadata": {
        "id": "ea923718"
      },
      "outputs": [],
      "source": [
        "ruler = nlp.add_pipe('entity_ruler')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "id": "2df278e4",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2df278e4",
        "outputId": "cde1ebb4-7642-43ab-833f-79cfe01e2652"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'summary': {'tok2vec': {'assigns': ['doc.tensor'],\n",
              "   'requires': [],\n",
              "   'scores': [],\n",
              "   'retokenizes': False},\n",
              "  'tagger': {'assigns': ['token.tag'],\n",
              "   'requires': [],\n",
              "   'scores': ['tag_acc'],\n",
              "   'retokenizes': False},\n",
              "  'parser': {'assigns': ['token.dep',\n",
              "    'token.head',\n",
              "    'token.is_sent_start',\n",
              "    'doc.sents'],\n",
              "   'requires': [],\n",
              "   'scores': ['dep_uas',\n",
              "    'dep_las',\n",
              "    'dep_las_per_type',\n",
              "    'sents_p',\n",
              "    'sents_r',\n",
              "    'sents_f'],\n",
              "   'retokenizes': False},\n",
              "  'attribute_ruler': {'assigns': [],\n",
              "   'requires': [],\n",
              "   'scores': [],\n",
              "   'retokenizes': False},\n",
              "  'lemmatizer': {'assigns': ['token.lemma'],\n",
              "   'requires': [],\n",
              "   'scores': ['lemma_acc'],\n",
              "   'retokenizes': False},\n",
              "  'ner': {'assigns': ['doc.ents', 'token.ent_iob', 'token.ent_type'],\n",
              "   'requires': [],\n",
              "   'scores': ['ents_f', 'ents_p', 'ents_r', 'ents_per_type'],\n",
              "   'retokenizes': False},\n",
              "  'entity_ruler': {'assigns': ['doc.ents', 'token.ent_type', 'token.ent_iob'],\n",
              "   'requires': [],\n",
              "   'scores': ['ents_f', 'ents_p', 'ents_r', 'ents_per_type'],\n",
              "   'retokenizes': False}},\n",
              " 'problems': {'tok2vec': [],\n",
              "  'tagger': [],\n",
              "  'parser': [],\n",
              "  'attribute_ruler': [],\n",
              "  'lemmatizer': [],\n",
              "  'ner': [],\n",
              "  'entity_ruler': []},\n",
              " 'attrs': {'token.dep': {'assigns': ['parser'], 'requires': []},\n",
              "  'doc.ents': {'assigns': ['ner', 'entity_ruler'], 'requires': []},\n",
              "  'token.tag': {'assigns': ['tagger'], 'requires': []},\n",
              "  'token.head': {'assigns': ['parser'], 'requires': []},\n",
              "  'doc.sents': {'assigns': ['parser'], 'requires': []},\n",
              "  'token.ent_iob': {'assigns': ['ner', 'entity_ruler'], 'requires': []},\n",
              "  'doc.tensor': {'assigns': ['tok2vec'], 'requires': []},\n",
              "  'token.ent_type': {'assigns': ['ner', 'entity_ruler'], 'requires': []},\n",
              "  'token.lemma': {'assigns': ['lemmatizer'], 'requires': []},\n",
              "  'token.is_sent_start': {'assigns': ['parser'], 'requires': []}}}"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ],
      "source": [
        "nlp.analyze_pipes()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "id": "919ddc21",
      "metadata": {
        "id": "919ddc21"
      },
      "outputs": [],
      "source": [
        "# adding patterns in the pipelines\n",
        "patterns = [\n",
        "    {'label': 'GPE', 'pattern': 'Azkaban'}\n",
        "]\n",
        "ruler.add_patterns(patterns)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "id": "fcbbb516",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fcbbb516",
        "outputId": "b1abce46-d216-4da3-d143-0cb2b238606f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Azkaban ORG\n",
            "Harry Potter PERSON\n"
          ]
        }
      ],
      "source": [
        "doc2 = nlp(text)\n",
        "for ent in doc2.ents:\n",
        "    print(ent.text, ent.label_) # IT DIDN'T WORK!!!"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "ftjXZqN0jQT_"
      },
      "id": "ftjXZqN0jQT_",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "id": "6f8e1610",
      "metadata": {
        "id": "6f8e1610"
      },
      "source": [
        "\n",
        "The `ner` should be after the `entity_ruler` pipe in order for `Azkaban` to be categorized as `GPE`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "id": "a498faf6",
      "metadata": {
        "id": "a498faf6"
      },
      "outputs": [],
      "source": [
        "nlp2 = spacy.load('en_core_web_sm')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "id": "a86ba0bd",
      "metadata": {
        "id": "a86ba0bd"
      },
      "outputs": [],
      "source": [
        "# to add the entity_ruler before ner, the parameter `before` is sent\n",
        "ruler = nlp2.add_pipe('entity_ruler', before='ner')\n",
        "patterns = [\n",
        "    {'label': 'GPE', 'pattern': 'Azkaban'}\n",
        "]\n",
        "ruler.add_patterns(patterns)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "id": "33a70c68",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "33a70c68",
        "outputId": "f3af0596-b0ef-433c-ef89-316ae81436e0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Azkaban GPE\n",
            "Harry Potter PERSON\n"
          ]
        }
      ],
      "source": [
        "doc = nlp2(text)\n",
        "\n",
        "for ent in doc.ents:\n",
        "    print(ent.text, ent.label_) # works!!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "id": "2d621d01",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2d621d01",
        "outputId": "72aa611c-a08f-40a2-a37a-f68ef6118ef9"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'summary': {'tok2vec': {'assigns': ['doc.tensor'],\n",
              "   'requires': [],\n",
              "   'scores': [],\n",
              "   'retokenizes': False},\n",
              "  'tagger': {'assigns': ['token.tag'],\n",
              "   'requires': [],\n",
              "   'scores': ['tag_acc'],\n",
              "   'retokenizes': False},\n",
              "  'parser': {'assigns': ['token.dep',\n",
              "    'token.head',\n",
              "    'token.is_sent_start',\n",
              "    'doc.sents'],\n",
              "   'requires': [],\n",
              "   'scores': ['dep_uas',\n",
              "    'dep_las',\n",
              "    'dep_las_per_type',\n",
              "    'sents_p',\n",
              "    'sents_r',\n",
              "    'sents_f'],\n",
              "   'retokenizes': False},\n",
              "  'attribute_ruler': {'assigns': [],\n",
              "   'requires': [],\n",
              "   'scores': [],\n",
              "   'retokenizes': False},\n",
              "  'lemmatizer': {'assigns': ['token.lemma'],\n",
              "   'requires': [],\n",
              "   'scores': ['lemma_acc'],\n",
              "   'retokenizes': False},\n",
              "  'entity_ruler': {'assigns': ['doc.ents', 'token.ent_type', 'token.ent_iob'],\n",
              "   'requires': [],\n",
              "   'scores': ['ents_f', 'ents_p', 'ents_r', 'ents_per_type'],\n",
              "   'retokenizes': False},\n",
              "  'ner': {'assigns': ['doc.ents', 'token.ent_iob', 'token.ent_type'],\n",
              "   'requires': [],\n",
              "   'scores': ['ents_f', 'ents_p', 'ents_r', 'ents_per_type'],\n",
              "   'retokenizes': False}},\n",
              " 'problems': {'tok2vec': [],\n",
              "  'tagger': [],\n",
              "  'parser': [],\n",
              "  'attribute_ruler': [],\n",
              "  'lemmatizer': [],\n",
              "  'entity_ruler': [],\n",
              "  'ner': []},\n",
              " 'attrs': {'token.dep': {'assigns': ['parser'], 'requires': []},\n",
              "  'doc.ents': {'assigns': ['entity_ruler', 'ner'], 'requires': []},\n",
              "  'token.tag': {'assigns': ['tagger'], 'requires': []},\n",
              "  'token.head': {'assigns': ['parser'], 'requires': []},\n",
              "  'doc.sents': {'assigns': ['parser'], 'requires': []},\n",
              "  'token.ent_iob': {'assigns': ['entity_ruler', 'ner'], 'requires': []},\n",
              "  'doc.tensor': {'assigns': ['tok2vec'], 'requires': []},\n",
              "  'token.ent_type': {'assigns': ['entity_ruler', 'ner'], 'requires': []},\n",
              "  'token.lemma': {'assigns': ['lemmatizer'], 'requires': []},\n",
              "  'token.is_sent_start': {'assigns': ['parser'], 'requires': []}}}"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ],
      "source": [
        "nlp2.analyze_pipes()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from spacy import displacy\n",
        "displacy.render(doc, style='ent', jupyter=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "id": "xYXtuw98j_xT",
        "outputId": "f14420c4-3ed0-4333-9b72-4bddf22c6c34"
      },
      "id": "xYXtuw98j_xT",
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<span class=\"tex2jax_ignore\"><div class=\"entities\" style=\"line-height: 2.5; direction: ltr\">\n",
              "<mark class=\"entity\" style=\"background: #feca74; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
              "    Azkaban\n",
              "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">GPE</span>\n",
              "</mark>\n",
              " was referenced in \n",
              "<mark class=\"entity\" style=\"background: #aa9cfc; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
              "    Harry Potter\n",
              "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">PERSON</span>\n",
              "</mark>\n",
              ".</div></span>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "displacy.render(doc, style='dep', jupyter=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 333
        },
        "id": "EyWLKdXtkVmm",
        "outputId": "b5c0b494-b11b-4b0b-ac29-361ae3a6e904"
      },
      "id": "EyWLKdXtkVmm",
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<span class=\"tex2jax_ignore\"><svg xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\" xml:lang=\"en\" id=\"de5c322ad3fc44b7a256068e25f46ccc-0\" class=\"displacy\" width=\"1100\" height=\"312.0\" direction=\"ltr\" style=\"max-width: none; height: 312.0px; color: #000000; background: #ffffff; font-family: Arial; direction: ltr\">\n",
              "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"222.0\">\n",
              "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"50\">Azkaban</tspan>\n",
              "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"50\">ADJ</tspan>\n",
              "</text>\n",
              "\n",
              "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"222.0\">\n",
              "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"225\">was</tspan>\n",
              "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"225\">AUX</tspan>\n",
              "</text>\n",
              "\n",
              "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"222.0\">\n",
              "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"400\">referenced</tspan>\n",
              "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"400\">VERB</tspan>\n",
              "</text>\n",
              "\n",
              "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"222.0\">\n",
              "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"575\">in</tspan>\n",
              "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"575\">ADP</tspan>\n",
              "</text>\n",
              "\n",
              "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"222.0\">\n",
              "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"750\">Harry</tspan>\n",
              "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"750\">PROPN</tspan>\n",
              "</text>\n",
              "\n",
              "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"222.0\">\n",
              "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"925\">Potter.</tspan>\n",
              "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"925\">PROPN</tspan>\n",
              "</text>\n",
              "\n",
              "<g class=\"displacy-arrow\">\n",
              "    <path class=\"displacy-arc\" id=\"arrow-de5c322ad3fc44b7a256068e25f46ccc-0-0\" stroke-width=\"2px\" d=\"M70,177.0 C70,2.0 400.0,2.0 400.0,177.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
              "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
              "        <textPath xlink:href=\"#arrow-de5c322ad3fc44b7a256068e25f46ccc-0-0\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">nsubjpass</textPath>\n",
              "    </text>\n",
              "    <path class=\"displacy-arrowhead\" d=\"M70,179.0 L62,167.0 78,167.0\" fill=\"currentColor\"/>\n",
              "</g>\n",
              "\n",
              "<g class=\"displacy-arrow\">\n",
              "    <path class=\"displacy-arc\" id=\"arrow-de5c322ad3fc44b7a256068e25f46ccc-0-1\" stroke-width=\"2px\" d=\"M245,177.0 C245,89.5 395.0,89.5 395.0,177.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
              "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
              "        <textPath xlink:href=\"#arrow-de5c322ad3fc44b7a256068e25f46ccc-0-1\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">auxpass</textPath>\n",
              "    </text>\n",
              "    <path class=\"displacy-arrowhead\" d=\"M245,179.0 L237,167.0 253,167.0\" fill=\"currentColor\"/>\n",
              "</g>\n",
              "\n",
              "<g class=\"displacy-arrow\">\n",
              "    <path class=\"displacy-arc\" id=\"arrow-de5c322ad3fc44b7a256068e25f46ccc-0-2\" stroke-width=\"2px\" d=\"M420,177.0 C420,89.5 570.0,89.5 570.0,177.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
              "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
              "        <textPath xlink:href=\"#arrow-de5c322ad3fc44b7a256068e25f46ccc-0-2\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">prep</textPath>\n",
              "    </text>\n",
              "    <path class=\"displacy-arrowhead\" d=\"M570.0,179.0 L578.0,167.0 562.0,167.0\" fill=\"currentColor\"/>\n",
              "</g>\n",
              "\n",
              "<g class=\"displacy-arrow\">\n",
              "    <path class=\"displacy-arc\" id=\"arrow-de5c322ad3fc44b7a256068e25f46ccc-0-3\" stroke-width=\"2px\" d=\"M770,177.0 C770,89.5 920.0,89.5 920.0,177.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
              "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
              "        <textPath xlink:href=\"#arrow-de5c322ad3fc44b7a256068e25f46ccc-0-3\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">compound</textPath>\n",
              "    </text>\n",
              "    <path class=\"displacy-arrowhead\" d=\"M770,179.0 L762,167.0 778,167.0\" fill=\"currentColor\"/>\n",
              "</g>\n",
              "\n",
              "<g class=\"displacy-arrow\">\n",
              "    <path class=\"displacy-arc\" id=\"arrow-de5c322ad3fc44b7a256068e25f46ccc-0-4\" stroke-width=\"2px\" d=\"M595,177.0 C595,2.0 925.0,2.0 925.0,177.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
              "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
              "        <textPath xlink:href=\"#arrow-de5c322ad3fc44b7a256068e25f46ccc-0-4\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">pobj</textPath>\n",
              "    </text>\n",
              "    <path class=\"displacy-arrowhead\" d=\"M925.0,179.0 L933.0,167.0 917.0,167.0\" fill=\"currentColor\"/>\n",
              "</g>\n",
              "</svg></span>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "ng8PUS2kkiFe"
      },
      "id": "ng8PUS2kkiFe"
    },
    {
      "cell_type": "markdown",
      "source": [
        "# adding `film` as a custom label"
      ],
      "metadata": {
        "id": "JFz9QBn0jwkt"
      },
      "id": "JFz9QBn0jwkt"
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "id": "11e1541b",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "11e1541b",
        "outputId": "1fd79d5f-7d7b-4a10-8732-d29ae7ece465"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['tok2vec',\n",
              " 'tagger',\n",
              " 'parser',\n",
              " 'attribute_ruler',\n",
              " 'lemmatizer',\n",
              " 'entity_ruler',\n",
              " 'ner']"
            ]
          },
          "metadata": {},
          "execution_count": 24
        }
      ],
      "source": [
        "# adding `film` as a custom label\n",
        "\n",
        "nlp3 = spacy.load('en_core_web_sm')\n",
        "ruler = nlp3.add_pipe('entity_ruler', before = 'ner')\n",
        "nlp3.pipe_names"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "nlp3.disable_pipe(\"lemmatizer\")\n",
        "nlp3.pipe_names"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DUxIDSJfljZp",
        "outputId": "e3730e8a-b390-40fb-f318-81e341b10bfc"
      },
      "id": "DUxIDSJfljZp",
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['tok2vec', 'tagger', 'parser', 'attribute_ruler', 'entity_ruler', 'ner']"
            ]
          },
          "metadata": {},
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "572af698",
      "metadata": {
        "id": "572af698"
      },
      "outputs": [],
      "source": [
        "patterns = [\n",
        "    {'label': 'GPE', 'pattern': 'Azkaban'},\n",
        "    {'label': 'FILM', 'pattern': 'Harry Potter'}\n",
        "]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "id": "53bb8de1",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "53bb8de1",
        "outputId": "21191c81-cd6a-4e80-efc6-c2f0bebe4354"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Azkaban GPE\n",
            "Harry Potter PERSON\n"
          ]
        }
      ],
      "source": [
        "ruler.add_patterns(patterns)\n",
        "doc = nlp3(text)\n",
        "for ent in doc.ents:\n",
        "    print(ent.text, ent.label_)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "1bc1ba52",
      "metadata": {
        "id": "1bc1ba52"
      },
      "source": [
        "`NOTE`: But identifying `Harry Potter` as a film could cause a clash when a person is actually named as `Harry Potter`, due to our model recoginizing it as a film. This is called a `toponym`. A toponym resolution refers to when a word can have multiple label that are dependent upon context."
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Spacy with RegEx for multi-word tokens"
      ],
      "metadata": {
        "id": "3_J3W7yzoM7_"
      },
      "id": "3_J3W7yzoM7_"
    },
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "from spacy.tokens import Span\n",
        "\n",
        "text = \"Paul Newman was an American actor, but Paul Hollywood is a British TV Host. The name Paul is quite common.\"\n",
        "\n",
        "pattern = f\"Paul [A-Z]\\w+\"\n",
        "\n",
        "matches = re.finditer(pattern, text)\n",
        "for match in matches:\n",
        "    print(match)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uFWvNooCnh4U",
        "outputId": "8780b1b2-60b5-45c5-d9fe-e26461d99e90"
      },
      "id": "uFWvNooCnh4U",
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<re.Match object; span=(0, 11), match='Paul Newman'>\n",
            "<re.Match object; span=(39, 53), match='Paul Hollywood'>\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## If you want to add multi-word tokens, you have to search through the do for ALL of them if you use Span class to add them to  `doc.ents`"
      ],
      "metadata": {
        "id": "SMkBTanGqiX9"
      },
      "id": "SMkBTanGqiX9"
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "RwMf_5Tnqhc1"
      },
      "id": "RwMf_5Tnqhc1",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "text = \"Paul Newman was an American actor, but Paul Hollywood is a British TV Host. The name Paul is quite common.\"\n",
        "pattern = f\"Paul [A-Z]\\w+\"\n",
        "\n",
        "nlp = spacy.blank('en')\n",
        "doc = nlp(text)\n",
        "original_ents = list(doc.ents)\n",
        "print(\"tokens>\", [tok for tok in doc])\n",
        "print(\"original entities>\", [ent for ent in original_ents])\n",
        "mwt_ents = []\n",
        "\n",
        "for match in re.finditer(pattern, doc.text):\n",
        "    start, end = match.span()\n",
        "    span = doc.char_span(start, end)\n",
        "\n",
        "    if span is not None:\n",
        "      mwt_ents.append((span.start, span.end, span.text))\n",
        "\n",
        "print(\"new entities>\", [ent for ent in mwt_ents])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "U0XX5dWOok7U",
        "outputId": "1bf903d7-0b3d-4df0-c138-66592772ca33"
      },
      "id": "U0XX5dWOok7U",
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tokens> [Paul, Newman, was, an, American, actor, ,, but, Paul, Hollywood, is, a, British, TV, Host, ., The, name, Paul, is, quite, common, .]\n",
            "original entities> []\n",
            "new entities> [(0, 2, 'Paul Newman'), (8, 10, 'Paul Hollywood')]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for ent in mwt_ents:\n",
        "    start, end, _ = ent\n",
        "    person_ent = Span(doc, start, end, label = 'PERSON')\n",
        "    original_ents.append(person_ent)\n",
        "\n",
        "doc.ents = original_ents\n",
        "\n",
        "for ent in doc.ents:\n",
        "    print(ent.text, ent.label_)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f8KKyy2toZ-L",
        "outputId": "e3da8333-3e52-4f53-cdf8-c408bfc65889"
      },
      "id": "f8KKyy2toZ-L",
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Paul Newman PERSON\n",
            "Paul Hollywood PERSON\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "5jeOGemerSBQ"
      },
      "id": "5jeOGemerSBQ",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Do all this in a custom pipeline"
      ],
      "metadata": {
        "id": "AcMAH0CprSwN"
      },
      "id": "AcMAH0CprSwN"
    },
    {
      "cell_type": "code",
      "source": [
        "# create a custom pipe\n",
        "from spacy.language import Language\n",
        "import re\n",
        "\n",
        "@Language.component('paul_ner')\n",
        "def paul_ner(doc):\n",
        "    pattern = f\"Paul [A-Z]\\w+\"\n",
        "    original_ents = list(doc.ents)\n",
        "    mwt_ents = []\n",
        "\n",
        "    for match in re.finditer(pattern, doc.text):\n",
        "        start, end = match.span()\n",
        "        span = doc.char_span(start, end)\n",
        "\n",
        "        if span is not None:\n",
        "            mwt_ents.append((span.start, span.end, span.text))\n",
        "\n",
        "    for ent in mwt_ents:\n",
        "        start, end, _ = ent\n",
        "        person_ent = Span(doc, start, end, label = 'PERSON')\n",
        "        original_ents.append(person_ent)\n",
        "\n",
        "    doc.ents = original_ents\n",
        "\n",
        "    return(doc)"
      ],
      "metadata": {
        "id": "4qV6xGBloiG5"
      },
      "id": "4qV6xGBloiG5",
      "execution_count": 42,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "nlp2 = spacy.blank('en')\n",
        "nlp2.add_pipe('paul_ner')\n",
        "doc2 = nlp2(text)\n",
        "for ent in doc2.ents:\n",
        "    print(ent.text, ent.label_)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ljHmQzBbreZJ",
        "outputId": "7ba5d81f-9855-497b-aa13-0d73122ea4f0"
      },
      "id": "ljHmQzBbreZJ",
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Paul Newman PERSON\n",
            "Paul Hollywood PERSON\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "p0ZFYYePsSGE"
      },
      "id": "p0ZFYYePsSGE",
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.13"
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}