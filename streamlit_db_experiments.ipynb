{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/seanreed1111/colab-demos/blob/master/streamlit_db_experiments.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hA2qPZe9Uk9C"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/colinmcnamara/austin_langchain/blob/main/labs/LangChain_101/101-1-streamlit_streaming.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "id": "NWMAuo7V1Rmm"
      },
      "outputs": [],
      "source": [
        "# upload allconfig.json, dbconfig.json, DDL_for_LLM_upload.sql"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 46,
      "metadata": {
        "id": "TLMrWVStFdAx"
      },
      "outputs": [],
      "source": [
        "%pip install -qU langchain langchain_community langchain_openai streamlit loguru sqlalchemy pyodbc"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 47,
      "metadata": {
        "id": "gCUr3N5wvD_4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7ee37550-ad17-4066-ce6c-cbe15e754556"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
            "                                 Dload  Upload   Total   Spent    Left  Speed\n",
            "\r  0     0    0     0    0     0      0      0 --:--:-- --:--:-- --:--:--     0\r100   983  100   983    0     0  10779      0 --:--:-- --:--:-- --:--:-- 10802\n",
            "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
            "                                 Dload  Upload   Total   Spent    Left  Speed\n",
            "100    88  100    88    0     0    661      0 --:--:-- --:--:-- --:--:--   666\n"
          ]
        }
      ],
      "source": [
        "!bash install_drivers.sh > /dev/null"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ADD in the Callback Handler for the agent\n",
        "# - https://github.com/langchain-ai/langchain/issues/16489\n",
        "# - https://python.langchain.com/docs/use_cases/sql/agents\n",
        "https://api.python.langchain.com/en/latest/agent_toolkits/langchain_community.agent_toolkits.sql.base.create_sql_agent.html\n",
        "# - https://python.langchain.com/docs/integrations/toolkits/sql_database#use-sqldatabasetoolkit-within-an-agenthttps://python.langchain.com/docs/expression_language/cookbook/sql_db\n"
      ],
      "metadata": {
        "id": "IXQDJMJMhPO1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile streaming_app.py\n",
        "## adds openai-tools to agent tool creation BETTER, but still doesn't work\n",
        "\n",
        "# experiment-5-chat-and-execute-sql-with-WAB FAILURE\n",
        "# reference docs https://python.langchain.com/docs/integrations/toolkits/sql_database#use-sqldatabasetoolkit-within-an-agenthttps://python.langchain.com/docs/expression_language/cookbook/sql_db\n",
        "\n",
        "#https://python.langchain.com/docs/expression_language/cookbook/sql_db\n",
        "import streamlit as st\n",
        "from pathlib import Path\n",
        "import os, json\n",
        "from langchain_community.chat_models.azure_openai import AzureChatOpenAI #deprecated class, fix later\n",
        "from langchain.agents import create_sql_agent\n",
        "from langchain.sql_database import SQLDatabase #from langchain_community.utilities.sql_database import SQLDatabase\n",
        "from langchain.agents.agent_types import AgentType\n",
        "from langchain.callbacks import StreamlitCallbackHandler\n",
        "from langchain.agents.agent_toolkits import SQLDatabaseToolkit\n",
        "from langchain.schema import (\n",
        "    AIMessage,\n",
        "    HumanMessage,\n",
        "    SystemMessage,\n",
        "    ChatMessage\n",
        ")\n",
        "from sqlalchemy import create_engine\n",
        "import sqlite3\n",
        "import sqlalchemy\n",
        "from sqlalchemy import create_engine\n",
        "import urllib\n",
        "from loguru import logger\n",
        "\n",
        "LANGCHAIN_PROJECT = \"experiment-5-chat-and-execute-sql-with-WAB\"\n",
        "st.set_page_config(page_title=LANGCHAIN_PROJECT, page_icon=\"\")\n",
        "st.title(LANGCHAIN_PROJECT)\n",
        "\n",
        "def load_schema_from_file(file):\n",
        "    try:\n",
        "        with open(file, 'r') as f:\n",
        "            schema = f.read()\n",
        "        assert schema is not None\n",
        "        return schema\n",
        "\n",
        "    except Exception as e:\n",
        "        logger.error(e)\n",
        "\n",
        "def run_azure_config():\n",
        "    config_dir = Path.cwd()\n",
        "    openai_config_file_path = config_dir / \"allconfig.json\"\n",
        "    config_files = [openai_config_file_path]\n",
        "    config = {}\n",
        "    for file in config_files:\n",
        "        with open(file) as json_config:\n",
        "            config.update(json.load(json_config))\n",
        "    for k in config:\n",
        "        os.environ[k] = config[k]\n",
        "\n",
        "    os.environ[\"LANGCHAIN_PROJECT\"] = LANGCHAIN_PROJECT\n",
        "\n",
        "def get_wab_connection_string(db_config_file=\"dbconfig.json\"):\n",
        "    driver= '{ODBC Driver 18 for SQL Server}'\n",
        "    db_config_path = Path.cwd() / db_config_file\n",
        "\n",
        "    with open(db_config_path) as json_file:\n",
        "        dbconfig = json.load(json_file)\n",
        "\n",
        "    server = dbconfig['server']\n",
        "    database = dbconfig['database']\n",
        "    uid = dbconfig['username']\n",
        "    pwd = dbconfig['password']\n",
        "    port = int(dbconfig.get(\"port\",1433))\n",
        "    pyodbc_connection_string = f\"DRIVER={driver};SERVER={server};PORT={port};DATABASE={database};UID={uid};PWD={pwd};Encrypt=yes;Connection Timeout=30;READONLY=True;\"\n",
        "    params = urllib.parse.quote_plus(pyodbc_connection_string)\n",
        "    sqlalchemy_connection_string = f\"mssql+pyodbc:///?odbc_connect={params}\"\n",
        "    return sqlalchemy_connection_string\n",
        "\n",
        "\n",
        "run_azure_config()\n",
        "\n",
        "\n",
        "with st.sidebar:\n",
        "    text = st.text(\"SQL QUERIES WILL GO HERE\")\n",
        "    SCHEMA_FILEPATH  = (Path.cwd()) / \"DDL_for_LLM_upload.sql\"\n",
        "    uploaded_schema = f\"{load_schema_from_file(SCHEMA_FILEPATH)}\"\n",
        "    # schema = st.text(f\"{uploaded_schema}\")\n",
        "\n",
        "\n",
        "# User inputs\n",
        "# radio_opt = [\"Use sample Chinook database\", \"Connect to WAB Database\"]\n",
        "# selected_opt = st.sidebar.radio(label=\"Choose suitable option\", options=radio_opt)\n",
        "# if radio_opt.index(selected_opt) == 1:\n",
        "#     db_uri = st.sidebar.text_input(\n",
        "#         label=\"Database URI\", placeholder=\"azsqldb-genai-dataanalytics-sb\"\n",
        "#     )\n",
        "# else:\n",
        "#     db_uri = \"CHINOOKDB\"\n",
        "\n",
        "# Setup agent\n",
        "llm = AzureChatOpenAI(\n",
        "            temperature=0,\n",
        "            streaming=True,\n",
        "            max_tokens=1000,\n",
        "            azure_deployment=os.environ[\"AZURE_OPENAI_API_DEPLOYMENT_NAME_GPT35\"],\n",
        "            azure_endpoint=os.environ[\"AZURE_OPENAI_API_ENDPOINT\"],\n",
        "            model_name=os.environ[\"MODEL_NAME_GPT35\"],\n",
        "            openai_api_version=os.environ[\"AZURE_OPENAI_API_VERSION\"],\n",
        "            request_timeout=45,\n",
        "            verbose=True,\n",
        "            #callbacks=[stream_handler] PUSH THE HANDLING OF CALLBACKS TO THE AGENT\n",
        "        )\n",
        "\n",
        "\n",
        "@st.cache_resource(ttl=\"2h\")\n",
        "def get_db_engine(db_config_file=\"dbconfig.json\"):\n",
        "\n",
        "    def get_wab_connection_string(db_config_file=db_config_file):\n",
        "        driver= '{ODBC Driver 18 for SQL Server}'\n",
        "        db_config_path = Path.cwd() / db_config_file\n",
        "\n",
        "        with open(db_config_path) as json_file:\n",
        "            dbconfig = json.load(json_file)\n",
        "\n",
        "        server = dbconfig['server']\n",
        "        database = dbconfig['database']\n",
        "        uid = dbconfig['username']\n",
        "        pwd = dbconfig['password']\n",
        "        port = int(dbconfig.get(\"port\",1433))\n",
        "        pyodbc_connection_string = f\"DRIVER={driver};SERVER={server};PORT={port};DATABASE={database};UID={uid};PWD={pwd};Encrypt=yes;Connection Timeout=30;READONLY=True;\"\n",
        "        params = urllib.parse.quote_plus(pyodbc_connection_string)\n",
        "        sqlalchemy_connection_string = f\"mssql+pyodbc:///?odbc_connect={params}\"\n",
        "        return sqlalchemy_connection_string\n",
        "\n",
        "    return SQLDatabase.from_uri(database_uri=get_wab_connection_string())\n",
        "\n",
        "db=get_db_engine()\n",
        "toolkit = SQLDatabaseToolkit(db=db, llm=llm)\n",
        "agent = create_sql_agent(\n",
        "    llm=llm,\n",
        "    toolkit=toolkit,\n",
        "    verbose=True,\n",
        "    agent_type=\"openai-tools\",\n",
        ")\n",
        "\n",
        "with st.sidebar:\n",
        "    dialect = st.text(f\"dialect is {db.dialect}\")\n",
        "    table_names = st.text(f\"{db.get_usable_table_names()}\")\n",
        "    q = \"\"\"\n",
        "    SELECT TABLE_NAME\n",
        "    FROM INFORMATION_SCHEMA.TABLES\n",
        "    WHERE TABLE_SCHEMA = 'sandbox'\n",
        "    ORDER BY TABLE_NAME;\n",
        "    \"\"\"\n",
        "    sample = st.text('sample query -- db.run(q)')\n",
        "    result = st.text(f\"{db.run(q)}\")\n",
        "    table_info = st.text(f\"table info is {db.get_table_info_no_throw()}\")\n",
        "\n",
        "    context = st.text(f\"Your context is {toolkit.get_context()}\")\n",
        "    tools = st.text(f\" Your tools are {toolkit.get_tools()}\")\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "if \"messages\" not in st.session_state or st.sidebar.button(\"Clear message history\"):\n",
        "    # see https://blog.langchain.dev/llms-and-sql/\n",
        "    system_message = f\"\"\"\n",
        "    You are an expert at writing Mircosoft SQL database queries and T-SQL code.\n",
        "      When asked to write SQL queries use the following schema\n",
        "     \\n\\n\\n\n",
        "    {uploaded_schema}\n",
        "     \\n\\n\\n\n",
        "     After writing a query, score its estimated accuracy in answering the\n",
        "      user's question on a scale of 1-5, with 1 the lowest score and 5 the\n",
        "      highest possible. Respond with the query and the accuracy score. If you give\n",
        "      an accuracy score of 1 or 2, briefly state your reason.\n",
        "     \"\"\"\n",
        "    st.session_state[\"messages\"] = [{\"role\": \"system\", \"content\":system_message},\n",
        "                                    {\"role\": \"assistant\", \"content\": \"How can I help you?\"}\n",
        "                                    ]\n",
        "for msg in st.session_state.messages:\n",
        "    if msg[\"role\"] != \"system\":\n",
        "        st.chat_message(msg[\"role\"]).write(msg[\"content\"])\n",
        "\n",
        "user_query = st.chat_input(placeholder=\"Ask me anything!\")\n",
        "\n",
        "if user_query:\n",
        "    st.session_state.messages.append({\"role\": \"user\", \"content\": user_query})\n",
        "    st.chat_message(\"user\").write(user_query)\n",
        "\n",
        "    with st.chat_message(\"assistant\"):\n",
        "        st_cb = StreamlitCallbackHandler(st.container())\n",
        "        response = agent.invoke(user_query, callbacks=[st_cb])\n",
        "        st.session_state.messages.append({\"role\": \"assistant\", \"content\": response})\n",
        "        st.write(response)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eqI5nEZXK5_V",
        "outputId": "5dc467f4-a9d5-433c-bced-64e82ae3d54d"
      },
      "execution_count": 58,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overwriting streaming_app.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile streaming_app.py\n",
        "# experiment-5-chat-and-execute-sql-with-WAB FAILURE\n",
        "# reference docs https://python.langchain.com/docs/integrations/toolkits/sql_database#use-sqldatabasetoolkit-within-an-agenthttps://python.langchain.com/docs/expression_language/cookbook/sql_db\n",
        "\n",
        "#https://python.langchain.com/docs/expression_language/cookbook/sql_db\n",
        "\n",
        "\n",
        "#####\n",
        "'''\n",
        "Your context is {'table_info': '\\nCREATE TABLE [TELEPHONE_TYPE] (\\n\\tcolumn1 NVARCHAR(50) COLLATE SQL_Latin1_General_CP1_CI_AS NOT NULL, \\n\\tcolumn2 NVARCHAR(50) COLLATE SQL_Latin1_General_CP1_CI_AS NOT NULL\\n)\\n\\n/*\\n3 rows from TELEPHONE_TYPE table:\\ncolumn1\\tcolumn2\\nL\\tLandline\\nM\\tMobile\\nF\\tFax\\n*/', 'table_names': 'TELEPHONE_TYPE'}\n",
        "\n",
        "Your tools are [QuerySQLDataBaseTool(description=\"Input to this tool is a detailed and correct SQL query, output is a result from the database. If the query is not correct, an error message will be returned. If an error is returned, rewrite the query, check the query, and try again. If you encounter an issue with Unknown column 'xxxx' in 'field list', use sql_db_schema to query the correct table fields.\", db=<langchain_community.utilities.sql_database.SQLDatabase object at 0x7a9b5f0a6680>), InfoSQLDatabaseTool(description='Input to this tool is a comma-separated list of tables, output is the schema and sample rows for those tables. Be sure that the tables actually exist by calling sql_db_list_tables first! Example Input: table1, table2, table3', db=<langchain_community.utilities.sql_database.SQLDatabase object at 0x7a9b5f0a6680>), ListSQLDatabaseTool(db=<langchain_community.utilities.sql_database.SQLDatabase object at 0x7a9b5f0a6680>), QuerySQLCheckerTool(description='Use this tool to double check if your query is correct before executing it. Always use this tool before executing a query with sql_db_query!', db=<langchain_community.utilities.sql_database.SQLDatabase object at 0x7a9b5f0a6680>, llm=AzureChatOpenAI(verbose=True, client=<openai.resources.chat.completions.Completions object at 0x7a9b6f50cac0>, async_client=<openai.resources.chat.completions.AsyncCompletions object at 0x7a9b6f64a290>, model_name='gpt-35-turbo', temperature=0.0, openai_api_key='d7ca6573f74d4b97a97b9f8e58e4d75b', openai_proxy='', request_timeout=45.0, streaming=True, max_tokens=1000, azure_endpoint='https://opnai-genai-dataanlytics-sb.openai.azure.com/', deployment_name='mdl_gpt35_turbo_1106-wmp_genai_dataanalytics-sb', openai_api_version='2024-03-01-preview', openai_api_type='azure'), llm_chain=LLMChain(prompt=PromptTemplate(input_variables=['dialect', 'query'], template='\\n{query}\\nDouble check the {dialect} query above for common mistakes, including:\\n- Using NOT IN with NULL values\\n- Using UNION when UNION ALL should have been used\\n- Using BETWEEN for exclusive ranges\\n- Data type mismatch in predicates\\n- Properly quoting identifiers\\n- Using the correct number of arguments for functions\\n- Casting to the correct data type\\n- Using the proper columns for joins\\n\\nIf there are any of the above mistakes, rewrite the query. If there are no mistakes, just reproduce the original query.\\n\\nOutput the final SQL query only.\\n\\nSQL Query: '), llm=AzureChatOpenAI(verbose=True, client=<openai.resources.chat.completions.Completions object at 0x7a9b6f50cac0>, async_client=<openai.resources.chat.completions.AsyncCompletions object at 0x7a9b6f64a290>, model_name='gpt-35-turbo', temperature=0.0, openai_api_key='d7ca6573f74d4b97a97b9f8e58e4d75b', openai_proxy='', request_timeout=45.0, streaming=True, max_tokens=1000, azure_endpoint='https://opnai-genai-dataanlytics-sb.openai.azure.com/', deployment_name='mdl_gpt35_turbo_1106-wmp_genai_dataanalytics-sb', openai_api_version='2024-03-01-preview', openai_api_type='azure')))]\n",
        "'''\n",
        "\n",
        "# context is found here\n",
        "# https://api.python.langchain.com/en/latest/_modules/langchain_community/utilities/sql_database.html#SQLDatabase.get_context\n",
        "#######\n",
        "import streamlit as st\n",
        "from pathlib import Path\n",
        "import os, json\n",
        "from langchain_community.chat_models.azure_openai import AzureChatOpenAI #deprecated class, fix later\n",
        "from langchain.agents import create_sql_agent\n",
        "from langchain.sql_database import SQLDatabase #from langchain_community.utilities.sql_database import SQLDatabase\n",
        "from langchain.agents.agent_types import AgentType\n",
        "from langchain.callbacks import StreamlitCallbackHandler\n",
        "from langchain.agents.agent_toolkits import SQLDatabaseToolkit\n",
        "# from langchain.schema import (\n",
        "#     AIMessage,\n",
        "#     HumanMessage,\n",
        "#     SystemMessage,\n",
        "#     ChatMessage\n",
        "# )\n",
        "import sqlite3\n",
        "import sqlalchemy\n",
        "from sqlalchemy import create_engine\n",
        "import urllib\n",
        "from loguru import logger\n",
        "\n",
        "LANGCHAIN_PROJECT = \"experiment-5-chat-and-execute-sql-with-WAB\"\n",
        "st.set_page_config(page_title=LANGCHAIN_PROJECT, page_icon=\"\")\n",
        "st.title(LANGCHAIN_PROJECT)\n",
        "\n",
        "def load_schema_from_file(file):\n",
        "    try:\n",
        "        with open(file, 'r') as f:\n",
        "            schema = f.read()\n",
        "        assert schema is not None\n",
        "        return schema\n",
        "\n",
        "    except Exception as e:\n",
        "        logger.error(e)\n",
        "\n",
        "def run_azure_config():\n",
        "    config_dir = Path.cwd()\n",
        "    openai_config_file_path = config_dir / \"allconfig.json\"\n",
        "    config_files = [openai_config_file_path]\n",
        "    config = {}\n",
        "    for file in config_files:\n",
        "        with open(file) as json_config:\n",
        "            config.update(json.load(json_config))\n",
        "    for k in config:\n",
        "        os.environ[k] = config[k]\n",
        "\n",
        "    os.environ[\"LANGCHAIN_PROJECT\"] = LANGCHAIN_PROJECT\n",
        "\n",
        "# def get_wab_connection_string(db_config_file=\"dbconfig.json\"):\n",
        "#     driver= '{ODBC Driver 18 for SQL Server}'\n",
        "#     db_config_path = Path.cwd() / db_config_file\n",
        "\n",
        "#     with open(db_config_path) as json_file:\n",
        "#         dbconfig = json.load(json_file)\n",
        "\n",
        "#     server = dbconfig['server']\n",
        "#     database = dbconfig['database']\n",
        "#     uid = dbconfig['username']\n",
        "#     pwd = dbconfig['password']\n",
        "#     port = int(dbconfig.get(\"port\",1433))\n",
        "#     pyodbc_connection_string = f\"DRIVER={driver};SERVER={server};PORT={port};DATABASE={database};UID={uid};PWD={pwd};Encrypt=yes;Connection Timeout=30;READONLY=True;\"\n",
        "#     params = urllib.parse.quote_plus(pyodbc_connection_string)\n",
        "#     sqlalchemy_connection_string = f\"mssql+pyodbc:///?odbc_connect={params}\"\n",
        "#     return sqlalchemy_connection_string\n",
        "\n",
        "\n",
        "run_azure_config()\n",
        "\n",
        "\n",
        "with st.sidebar:\n",
        "    text = st.text(\"SQL QUERIES WILL GO HERE\")\n",
        "    SCHEMA_FILEPATH  = (Path.cwd()) / \"DDL_for_LLM_upload.sql\"\n",
        "    uploaded_schema = f\"{load_schema_from_file(SCHEMA_FILEPATH)}\"\n",
        "    # schema = st.text(f\"{uploaded_schema}\")\n",
        "\n",
        "# Setup agent\n",
        "llm = AzureChatOpenAI(\n",
        "            temperature=0,\n",
        "            streaming=True,\n",
        "            max_tokens=1000,\n",
        "            azure_deployment=os.environ[\"AZURE_OPENAI_API_DEPLOYMENT_NAME_GPT35\"],\n",
        "            azure_endpoint=os.environ[\"AZURE_OPENAI_API_ENDPOINT\"],\n",
        "            model_name=os.environ[\"MODEL_NAME_GPT35\"],\n",
        "            openai_api_version=os.environ[\"AZURE_OPENAI_API_VERSION\"],\n",
        "            request_timeout=45,\n",
        "            verbose=True,\n",
        "            #callbacks=[stream_handler] PUSH THE HANDLING OF CALLBACKS TO THE AGENT\n",
        "        )\n",
        "\n",
        "\n",
        "@st.cache_resource(ttl=\"2h\")\n",
        "def get_db_engine(db_config_file=\"dbconfig.json\"):\n",
        "\n",
        "    def get_wab_connection_string(db_config_file=db_config_file):\n",
        "        driver= '{ODBC Driver 18 for SQL Server}'\n",
        "        db_config_path = Path.cwd() / db_config_file\n",
        "\n",
        "        with open(db_config_path) as json_file:\n",
        "            dbconfig = json.load(json_file)\n",
        "\n",
        "        server = dbconfig['server']\n",
        "        database = dbconfig['database']\n",
        "        uid = dbconfig['username']\n",
        "        pwd = dbconfig['password']\n",
        "        port = int(dbconfig.get(\"port\",1433))\n",
        "        pyodbc_connection_string = f\"DRIVER={driver};SERVER={server};PORT={port};DATABASE={database};UID={uid};PWD={pwd};Encrypt=yes;Connection Timeout=30;READONLY=True;\"\n",
        "        params = urllib.parse.quote_plus(pyodbc_connection_string)\n",
        "        sqlalchemy_connection_string = f\"mssql+pyodbc:///?odbc_connect={params}\"\n",
        "        return sqlalchemy_connection_string\n",
        "\n",
        "    return SQLDatabase.from_uri(database_uri=get_wab_connection_string(),\n",
        "                               engine_args={\"schema\":\"sandbox\"}\n",
        "                               )\n",
        "\n",
        "db=get_db_engine()\n",
        "toolkit = SQLDatabaseToolkit(db=db, llm=llm)\n",
        "agent = create_sql_agent(\n",
        "    llm=llm,\n",
        "    toolkit=toolkit,\n",
        "    verbose=True,\n",
        "    agent_type=\"openai-tools\",\n",
        ")\n",
        "\n",
        "with st.sidebar:\n",
        "    dialect = st.text(f\"dialect is {db.dialect}\")\n",
        "    table_names = st.text(f\"usable_table names are {db.get_usable_table_names()}\")\n",
        "    table_info = st.text(f\"Table info is: {db.get_table_info_no_throw()}\")\n",
        "    q = \"\"\"\n",
        "    SELECT TABLE_NAME\n",
        "    FROM INFORMATION_SCHEMA.TABLES\n",
        "    WHERE TABLE_SCHEMA = 'sandbox'\n",
        "    ORDER BY TABLE_NAME;\n",
        "    \"\"\"\n",
        "    sample = st.text('sample query -- db.run(q)')\n",
        "    result = st.text(f\"{db.run(q)}\")\n",
        "    context = st.text(f\"Your context is {toolkit.get_context()}\")\n",
        "    tools = st.text(f\" Your tools are {toolkit.get_tools()}\")\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "if \"messages\" not in st.session_state or st.sidebar.button(\"Clear message history\"):\n",
        "    # see https://blog.langchain.dev/llms-and-sql/\n",
        "    system_message = f\"\"\"\n",
        "    You are an expert at writing Mircosoft SQL database queries and T-SQL code.\n",
        "      When asked to write SQL queries use the following schema\n",
        "     \\n\\n\\n\n",
        "    {uploaded_schema}\n",
        "     \\n\\n\\n\n",
        "     After writing a query, score its estimated accuracy in answering the\n",
        "      user's question on a scale of 1-5, with 1 the lowest score and 5 the\n",
        "      highest possible. Respond with the query and the accuracy score. If you give\n",
        "      an accuracy score of 1 or 2, briefly state your reason.\n",
        "     \"\"\"\n",
        "    st.session_state[\"messages\"] = [{\"role\": \"system\", \"content\":system_message},\n",
        "                                    {\"role\": \"assistant\", \"content\": \"How can I help you?\"}\n",
        "                                    ]\n",
        "for msg in st.session_state.messages:\n",
        "    if msg[\"role\"] != \"system\":\n",
        "        st.chat_message(msg[\"role\"]).write(msg[\"content\"])\n",
        "\n",
        "user_query = st.chat_input(placeholder=\"Ask me anything!\")\n",
        "\n",
        "if user_query:\n",
        "    st.session_state.messages.append({\"role\": \"user\", \"content\": user_query})\n",
        "    st.chat_message(\"user\").write(user_query)\n",
        "\n",
        "    with st.chat_message(\"assistant\"):\n",
        "        st_cb = StreamlitCallbackHandler(st.container())\n",
        "        response = agent.invoke(user_query, callbacks=[st_cb])\n",
        "        st.session_state.messages.append({\"role\": \"assistant\", \"content\": response})\n",
        "        st.write(response)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yY7u6n9TF_Yo",
        "outputId": "dc8b1a3c-1805-4423-c02b-b3eb15a659a4"
      },
      "execution_count": 60,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overwriting streaming_app.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile streaming_app.py\n",
        "# experiment-5-chat-and-execute-sql-with-WAB SUCCESS\n",
        "# reference docs https://python.langchain.com/docs/integrations/toolkits/sql_database#use-sqldatabasetoolkit-within-an-agenthttps://python.langchain.com/docs/expression_language/cookbook/sql_db\n",
        "\n",
        "#https://python.langchain.com/docs/expression_language/cookbook/sql_db\n",
        "\n",
        "# context is found here\n",
        "# https://api.python.langchain.com/en/latest/_modules/langchain_community/utilities/sql_database.html#SQLDatabase.get_context\n",
        "#######\n",
        "import streamlit as st\n",
        "from pathlib import Path\n",
        "import os, json\n",
        "from langchain_community.chat_models.azure_openai import AzureChatOpenAI #deprecated class, fix later\n",
        "from langchain.agents import create_sql_agent\n",
        "from langchain.sql_database import SQLDatabase #from langchain_community.utilities.sql_database import SQLDatabase\n",
        "from langchain.agents.agent_types import AgentType\n",
        "from langchain.callbacks import StreamlitCallbackHandler\n",
        "from langchain.agents.agent_toolkits import SQLDatabaseToolkit\n",
        "# from langchain.schema import (\n",
        "#     AIMessage,\n",
        "#     HumanMessage,\n",
        "#     SystemMessage,\n",
        "#     ChatMessage\n",
        "# )\n",
        "import sqlite3\n",
        "import sqlalchemy\n",
        "from sqlalchemy import create_engine\n",
        "import urllib\n",
        "from loguru import logger\n",
        "\n",
        "LANGCHAIN_PROJECT = \"experiment-5-chat-and-execute-sql-with-WAB\"\n",
        "st.set_page_config(page_title=LANGCHAIN_PROJECT, page_icon=\"\")\n",
        "st.title(LANGCHAIN_PROJECT)\n",
        "\n",
        "def load_schema_from_file(file):\n",
        "    try:\n",
        "        with open(file, 'r') as f:\n",
        "            schema = f.read()\n",
        "        assert schema is not None\n",
        "        return schema\n",
        "\n",
        "    except Exception as e:\n",
        "        logger.error(e)\n",
        "\n",
        "def run_azure_config():\n",
        "    config_dir = Path.cwd()\n",
        "    openai_config_file_path = config_dir / \"allconfig.json\"\n",
        "    config_files = [openai_config_file_path]\n",
        "    config = {}\n",
        "    for file in config_files:\n",
        "        with open(file) as json_config:\n",
        "            config.update(json.load(json_config))\n",
        "    for k in config:\n",
        "        os.environ[k] = config[k]\n",
        "\n",
        "    os.environ[\"LANGCHAIN_PROJECT\"] = LANGCHAIN_PROJECT\n",
        "\n",
        "# def get_wab_connection_string(db_config_file=\"dbconfig.json\"):\n",
        "#     driver= '{ODBC Driver 18 for SQL Server}'\n",
        "#     db_config_path = Path.cwd() / db_config_file\n",
        "\n",
        "#     with open(db_config_path) as json_file:\n",
        "#         dbconfig = json.load(json_file)\n",
        "\n",
        "#     server = dbconfig['server']\n",
        "#     database = dbconfig['database']\n",
        "#     uid = dbconfig['username']\n",
        "#     pwd = dbconfig['password']\n",
        "#     port = int(dbconfig.get(\"port\",1433))\n",
        "#     pyodbc_connection_string = f\"DRIVER={driver};SERVER={server};PORT={port};DATABASE={database};UID={uid};PWD={pwd};Encrypt=yes;Connection Timeout=30;READONLY=True;\"\n",
        "#     params = urllib.parse.quote_plus(pyodbc_connection_string)\n",
        "#     sqlalchemy_connection_string = f\"mssql+pyodbc:///?odbc_connect={params}\"\n",
        "#     return sqlalchemy_connection_string\n",
        "\n",
        "\n",
        "run_azure_config()\n",
        "\n",
        "# Setup agent\n",
        "llm = AzureChatOpenAI(\n",
        "            temperature=0,\n",
        "            streaming=True,\n",
        "            max_tokens=1000,\n",
        "            azure_deployment=os.environ[\"AZURE_OPENAI_API_DEPLOYMENT_NAME_GPT35\"],\n",
        "            azure_endpoint=os.environ[\"AZURE_OPENAI_API_ENDPOINT\"],\n",
        "            model_name=os.environ[\"MODEL_NAME_GPT35\"],\n",
        "            openai_api_version=os.environ[\"AZURE_OPENAI_API_VERSION\"],\n",
        "            request_timeout=45,\n",
        "            verbose=True,\n",
        "            #callbacks=[stream_handler] PUSH THE HANDLING OF CALLBACKS TO THE AGENT\n",
        "        )\n",
        "\n",
        "\n",
        "@st.cache_resource(ttl=\"2h\")\n",
        "def get_db_engine(db_config_file=\"dbconfig.json\"):\n",
        "\n",
        "    def get_wab_connection_string(db_config_file=db_config_file):\n",
        "        driver= '{ODBC Driver 18 for SQL Server}'\n",
        "        db_config_path = Path.cwd() / db_config_file\n",
        "\n",
        "        with open(db_config_path) as json_file:\n",
        "            dbconfig = json.load(json_file)\n",
        "\n",
        "        server = dbconfig['server']\n",
        "        database = dbconfig['database']\n",
        "        uid = dbconfig['username']\n",
        "        pwd = dbconfig['password']\n",
        "        port = int(dbconfig.get(\"port\",1433))\n",
        "        pyodbc_connection_string = f\"DRIVER={driver};SERVER={server};PORT={port};DATABASE={database};UID={uid};PWD={pwd};Encrypt=yes;Connection Timeout=30;READONLY=True;\"\n",
        "        params = urllib.parse.quote_plus(pyodbc_connection_string)\n",
        "        sqlalchemy_connection_string = f\"mssql+pyodbc:///?odbc_connect={params}\"\n",
        "        return sqlalchemy_connection_string\n",
        "\n",
        "    kwargs = {\"schema\":\"sandbox\"}\n",
        "    return SQLDatabase.from_uri(database_uri=get_wab_connection_string(),\n",
        "                               **kwargs\n",
        "                               )\n",
        "\n",
        "db=get_db_engine()\n",
        "toolkit = SQLDatabaseToolkit(db=db, llm=llm)\n",
        "agent = create_sql_agent(\n",
        "    llm=llm,\n",
        "    toolkit=toolkit,\n",
        "    verbose=True,\n",
        "    agent_type=\"openai-tools\",\n",
        ")\n",
        "\n",
        "with st.sidebar:\n",
        "    # text = st.text(\"SQL QUERIES WILL GO HERE\")\n",
        "    SCHEMA_FILEPATH  = (Path.cwd()) / \"DDL_for_LLM_upload.sql\"\n",
        "    uploaded_schema = f\"{load_schema_from_file(SCHEMA_FILEPATH)}\"\n",
        "    # schema = st.text(f\"{uploaded_schema}\")\n",
        "#    dialect = st.text(f\"dialect is {db.dialect}\")\n",
        "#    table_names = st.text(f\"usable_table names are {db.get_usable_table_names()}\")\n",
        "#    table_info = st.text(f\"Table info is: {db.get_table_info_no_throw()}\")\n",
        "    # q = \"\"\"\n",
        "    # SELECT TABLE_NAME\n",
        "    # FROM INFORMATION_SCHEMA.TABLES\n",
        "    # WHERE TABLE_SCHEMA = 'sandbox'\n",
        "    # ORDER BY TABLE_NAME;\n",
        "    # \"\"\"\n",
        "    # sample = st.text('sample query -- db.run(q)')\n",
        "    # result = st.text(f\"{db.run(q)}\")\n",
        "    context = st.text(f\"Your context is {toolkit.get_context()}\")\n",
        "    tools = st.text(f\" Your tools are {toolkit.get_tools()}\")\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "if \"messages\" not in st.session_state or st.sidebar.button(\"Clear message history\"):\n",
        "    # see https://blog.langchain.dev/llms-and-sql/\n",
        "    system_message = f\"\"\"\n",
        "    You are an expert at writing Mircosoft SQL database queries and T-SQL code.\n",
        "      When asked to write SQL queries use the following schema\n",
        "     \\n\\n\\n\n",
        "    {uploaded_schema}\n",
        "     \\n\\n\\n\n",
        "     After writing a query, score its estimated accuracy in answering the\n",
        "      user's question on a scale of 1-5, with 1 the lowest score and 5 the\n",
        "      highest possible. Respond with the query and the accuracy score. If you give\n",
        "      an accuracy score of 1 or 2, briefly state your reason.\n",
        "     \"\"\"\n",
        "    st.session_state[\"messages\"] = [{\"role\": \"system\", \"content\":system_message},\n",
        "                                    {\"role\": \"assistant\", \"content\": \"How can I help you?\"}\n",
        "                                    ]\n",
        "for msg in st.session_state.messages:\n",
        "    if msg[\"role\"] != \"system\":\n",
        "        st.chat_message(msg[\"role\"]).write(msg[\"content\"])\n",
        "\n",
        "user_query = st.chat_input(placeholder=\"Ask me anything!\")\n",
        "\n",
        "if user_query:\n",
        "    st.session_state.messages.append({\"role\": \"user\", \"content\": user_query})\n",
        "    st.chat_message(\"user\").write(user_query)\n",
        "\n",
        "    with st.chat_message(\"assistant\"):\n",
        "        st_cb = StreamlitCallbackHandler(st.container())\n",
        "        response = agent.invoke(user_query, callbacks=[st_cb])\n",
        "        st.session_state.messages.append({\"role\": \"assistant\", \"content\": response})\n",
        "        st.write(response)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wvsNabsVG5H6",
        "outputId": "5a854a34-0f7e-4ab5-f247-68d59c11e576"
      },
      "execution_count": 66,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overwriting streaming_app.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile streaming_app.py\n",
        "# experiment-5-chat-and-execute-sql-with-WAB FAILURE\n",
        "# reference docs https://python.langchain.com/docs/integrations/toolkits/sql_database#use-sqldatabasetoolkit-within-an-agenthttps://python.langchain.com/docs/expression_language/cookbook/sql_db\n",
        "\n",
        "#https://python.langchain.com/docs/expression_language/cookbook/sql_db\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "##### this function is garbage\n",
        "#[docs]    def get_usable_table_names(self) -> Iterable[str]:\n",
        "#        \"\"\"Get names of tables available.\"\"\"\n",
        "#        if self._include_tables:\n",
        "#            return sorted(self._include_tables)\n",
        "#        return sorted(self._all_tables - self._ignore_tables)\n",
        "#####\n",
        "'''\n",
        "Your context is {'table_info': '\\nCREATE TABLE [TELEPHONE_TYPE] (\\n\\tcolumn1 NVARCHAR(50) COLLATE SQL_Latin1_General_CP1_CI_AS NOT NULL, \\n\\tcolumn2 NVARCHAR(50) COLLATE SQL_Latin1_General_CP1_CI_AS NOT NULL\\n)\\n\\n/*\\n3 rows from TELEPHONE_TYPE table:\\ncolumn1\\tcolumn2\\nL\\tLandline\\nM\\tMobile\\nF\\tFax\\n*/', 'table_names': 'TELEPHONE_TYPE'}\n",
        "\n",
        "Your tools are [QuerySQLDataBaseTool(description=\"Input to this tool is a detailed and correct SQL query, output is a result from the database. If the query is not correct, an error message will be returned. If an error is returned, rewrite the query, check the query, and try again. If you encounter an issue with Unknown column 'xxxx' in 'field list', use sql_db_schema to query the correct table fields.\", db=<langchain_community.utilities.sql_database.SQLDatabase object at 0x7a9b5f0a6680>), InfoSQLDatabaseTool(description='Input to this tool is a comma-separated list of tables, output is the schema and sample rows for those tables. Be sure that the tables actually exist by calling sql_db_list_tables first! Example Input: table1, table2, table3', db=<langchain_community.utilities.sql_database.SQLDatabase object at 0x7a9b5f0a6680>), ListSQLDatabaseTool(db=<langchain_community.utilities.sql_database.SQLDatabase object at 0x7a9b5f0a6680>), QuerySQLCheckerTool(description='Use this tool to double check if your query is correct before executing it. Always use this tool before executing a query with sql_db_query!', db=<langchain_community.utilities.sql_database.SQLDatabase object at 0x7a9b5f0a6680>, llm=AzureChatOpenAI(verbose=True, client=<openai.resources.chat.completions.Completions object at 0x7a9b6f50cac0>, async_client=<openai.resources.chat.completions.AsyncCompletions object at 0x7a9b6f64a290>, model_name='gpt-35-turbo', temperature=0.0, openai_api_key='d7ca6573f74d4b97a97b9f8e58e4d75b', openai_proxy='', request_timeout=45.0, streaming=True, max_tokens=1000, azure_endpoint='https://opnai-genai-dataanlytics-sb.openai.azure.com/', deployment_name='mdl_gpt35_turbo_1106-wmp_genai_dataanalytics-sb', openai_api_version='2024-03-01-preview', openai_api_type='azure'), llm_chain=LLMChain(prompt=PromptTemplate(input_variables=['dialect', 'query'], template='\\n{query}\\nDouble check the {dialect} query above for common mistakes, including:\\n- Using NOT IN with NULL values\\n- Using UNION when UNION ALL should have been used\\n- Using BETWEEN for exclusive ranges\\n- Data type mismatch in predicates\\n- Properly quoting identifiers\\n- Using the correct number of arguments for functions\\n- Casting to the correct data type\\n- Using the proper columns for joins\\n\\nIf there are any of the above mistakes, rewrite the query. If there are no mistakes, just reproduce the original query.\\n\\nOutput the final SQL query only.\\n\\nSQL Query: '), llm=AzureChatOpenAI(verbose=True, client=<openai.resources.chat.completions.Completions object at 0x7a9b6f50cac0>, async_client=<openai.resources.chat.completions.AsyncCompletions object at 0x7a9b6f64a290>, model_name='gpt-35-turbo', temperature=0.0, openai_api_key='d7ca6573f74d4b97a97b9f8e58e4d75b', openai_proxy='', request_timeout=45.0, streaming=True, max_tokens=1000, azure_endpoint='https://opnai-genai-dataanlytics-sb.openai.azure.com/', deployment_name='mdl_gpt35_turbo_1106-wmp_genai_dataanalytics-sb', openai_api_version='2024-03-01-preview', openai_api_type='azure')))]\n",
        "'''\n",
        "\n",
        "# context is found here\n",
        "# https://api.python.langchain.com/en/latest/_modules/langchain_community/utilities/sql_database.html#SQLDatabase.get_context\n",
        "#######\n",
        "import streamlit as st\n",
        "from pathlib import Path\n",
        "import os, json\n",
        "from langchain_community.chat_models.azure_openai import AzureChatOpenAI #deprecated class, fix later\n",
        "from langchain.agents import create_sql_agent\n",
        "from langchain.sql_database import SQLDatabase #from langchain_community.utilities.sql_database import SQLDatabase\n",
        "from langchain.agents.agent_types import AgentType\n",
        "from langchain.callbacks import StreamlitCallbackHandler\n",
        "from langchain.agents.agent_toolkits import SQLDatabaseToolkit\n",
        "# from langchain.schema import (\n",
        "#     AIMessage,\n",
        "#     HumanMessage,\n",
        "#     SystemMessage,\n",
        "#     ChatMessage\n",
        "# )\n",
        "import sqlite3\n",
        "import sqlalchemy\n",
        "from sqlalchemy import create_engine\n",
        "import urllib\n",
        "from loguru import logger\n",
        "\n",
        "LANGCHAIN_PROJECT = \"experiment-5-chat-and-execute-sql-with-WAB\"\n",
        "st.set_page_config(page_title=LANGCHAIN_PROJECT, page_icon=\"\")\n",
        "st.title(LANGCHAIN_PROJECT)\n",
        "\n",
        "def load_schema_from_file(file):\n",
        "    try:\n",
        "        with open(file, 'r') as f:\n",
        "            schema = f.read()\n",
        "        assert schema is not None\n",
        "        return schema\n",
        "\n",
        "    except Exception as e:\n",
        "        logger.error(e)\n",
        "\n",
        "def run_azure_config():\n",
        "    config_dir = Path.cwd()\n",
        "    openai_config_file_path = config_dir / \"allconfig.json\"\n",
        "    config_files = [openai_config_file_path]\n",
        "    config = {}\n",
        "    for file in config_files:\n",
        "        with open(file) as json_config:\n",
        "            config.update(json.load(json_config))\n",
        "    for k in config:\n",
        "        os.environ[k] = config[k]\n",
        "\n",
        "    os.environ[\"LANGCHAIN_PROJECT\"] = LANGCHAIN_PROJECT\n",
        "\n",
        "# def get_wab_connection_string(db_config_file=\"dbconfig.json\"):\n",
        "#     driver= '{ODBC Driver 18 for SQL Server}'\n",
        "#     db_config_path = Path.cwd() / db_config_file\n",
        "\n",
        "#     with open(db_config_path) as json_file:\n",
        "#         dbconfig = json.load(json_file)\n",
        "\n",
        "#     server = dbconfig['server']\n",
        "#     database = dbconfig['database']\n",
        "#     uid = dbconfig['username']\n",
        "#     pwd = dbconfig['password']\n",
        "#     port = int(dbconfig.get(\"port\",1433))\n",
        "#     pyodbc_connection_string = f\"DRIVER={driver};SERVER={server};PORT={port};DATABASE={database};UID={uid};PWD={pwd};Encrypt=yes;Connection Timeout=30;READONLY=True;\"\n",
        "#     params = urllib.parse.quote_plus(pyodbc_connection_string)\n",
        "#     sqlalchemy_connection_string = f\"mssql+pyodbc:///?odbc_connect={params}\"\n",
        "#     return sqlalchemy_connection_string\n",
        "\n",
        "\n",
        "run_azure_config()\n",
        "\n",
        "# Setup agent\n",
        "llm = AzureChatOpenAI(\n",
        "            temperature=0,\n",
        "            streaming=True,\n",
        "            max_tokens=1000,\n",
        "            azure_deployment=os.environ[\"AZURE_OPENAI_API_DEPLOYMENT_NAME_GPT35\"],\n",
        "            azure_endpoint=os.environ[\"AZURE_OPENAI_API_ENDPOINT\"],\n",
        "            model_name=os.environ[\"MODEL_NAME_GPT35\"],\n",
        "            openai_api_version=os.environ[\"AZURE_OPENAI_API_VERSION\"],\n",
        "            request_timeout=45,\n",
        "            verbose=True,\n",
        "            #callbacks=[stream_handler] PUSH THE HANDLING OF CALLBACKS TO THE AGENT\n",
        "        )\n",
        "\n",
        "\n",
        "@st.cache_resource(ttl=\"2h\")\n",
        "def get_db_engine(db_config_file=\"dbconfig.json\"):\n",
        "\n",
        "    def get_wab_connection_string(db_config_file=db_config_file):\n",
        "        driver= '{ODBC Driver 18 for SQL Server}'\n",
        "        db_config_path = Path.cwd() / db_config_file\n",
        "\n",
        "        with open(db_config_path) as json_file:\n",
        "            dbconfig = json.load(json_file)\n",
        "\n",
        "        server = dbconfig['server']\n",
        "        database = dbconfig['database']\n",
        "        uid = dbconfig['username']\n",
        "        pwd = dbconfig['password']\n",
        "        port = int(dbconfig.get(\"port\",1433))\n",
        "        pyodbc_connection_string = f\"DRIVER={driver};SERVER={server};PORT={port};DATABASE={database};UID={uid};PWD={pwd};Encrypt=yes;Connection Timeout=30;READONLY=True;\"\n",
        "        params = urllib.parse.quote_plus(pyodbc_connection_string)\n",
        "        sqlalchemy_connection_string = f\"mssql+pyodbc:///?odbc_connect={params}\"\n",
        "        return sqlalchemy_connection_string\n",
        "\n",
        "    kwargs = {\"schema\":\"sandbox\"}\n",
        "    return SQLDatabase.from_uri(get_wab_connection_string(),**kwargs)\n",
        "\n",
        "db=get_db_engine()\n",
        "toolkit = SQLDatabaseToolkit(db=db, llm=llm)\n",
        "agent = create_sql_agent(\n",
        "    llm=llm,\n",
        "    toolkit=toolkit,\n",
        "    verbose=True,\n",
        "    agent_type=\"openai-tools\",\n",
        ")\n",
        "\n",
        "with st.sidebar:\n",
        "    # text = st.text(\"SQL QUERIES WILL GO HERE\")\n",
        "    SCHEMA_FILEPATH  = (Path.cwd()) / \"DDL_for_LLM_upload.sql\"\n",
        "    uploaded_schema = f\"{load_schema_from_file(SCHEMA_FILEPATH)}\"\n",
        "    # schema = st.text(f\"{uploaded_schema}\")\n",
        "    dialect = st.text(f\"dialect is {db.dialect}\")\n",
        "    all_tables = st.text(f\"all tables = {db._all_tables}\")\n",
        "    include_tables = st.text(f\"include tables = {db._include_tables}\")\n",
        "    ignore_tables = st.text(f\"ignore tables = {db._ignore_tables}\")\n",
        "    table_names = st.text(f\"usable_table names are {list(db.get_usable_table_names())}\")\n",
        "    table_info = st.text(f\"Table info is: {db.get_table_info_no_throw()}\")\n",
        "    # q = \"\"\"\n",
        "    # SELECT TABLE_NAME\n",
        "    # FROM INFORMATION_SCHEMA.TABLES\n",
        "    # WHERE TABLE_SCHEMA = 'sandbox'\n",
        "    # ORDER BY TABLE_NAME;\n",
        "    # \"\"\"\n",
        "    # sample = st.text('sample query -- db.run(q)')\n",
        "    # result = st.text(f\"{db.run(q)}\")\n",
        "    # context = st.text(f\"Your context is {toolkit.get_context()}\")\n",
        "    # tools = st.text(f\" Your tools are {toolkit.get_tools()}\")\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "if \"messages\" not in st.session_state or st.sidebar.button(\"Clear message history\"):\n",
        "    # see https://blog.langchain.dev/llms-and-sql/\n",
        "    system_message = f\"\"\"\n",
        "    You are an expert at writing Mircosoft SQL database queries and T-SQL code.\n",
        "      When asked to write SQL queries use the following schema\n",
        "     \\n\\n\\n\n",
        "    {uploaded_schema}\n",
        "     \\n\\n\\n\n",
        "     After writing a query, score its estimated accuracy in answering the\n",
        "      user's question on a scale of 1-5, with 1 the lowest score and 5 the\n",
        "      highest possible. Respond with the query and the accuracy score. If you give\n",
        "      an accuracy score of 1 or 2, briefly state your reason.\n",
        "     \"\"\"\n",
        "    st.session_state[\"messages\"] = [{\"role\": \"system\", \"content\":system_message},\n",
        "                                    {\"role\": \"assistant\", \"content\": \"How can I help you?\"}\n",
        "                                    ]\n",
        "for msg in st.session_state.messages:\n",
        "    if msg[\"role\"] != \"system\":\n",
        "        st.chat_message(msg[\"role\"]).write(msg[\"content\"])\n",
        "\n",
        "user_query = st.chat_input(placeholder=\"Ask me anything!\")\n",
        "\n",
        "if user_query:\n",
        "    st.session_state.messages.append({\"role\": \"user\", \"content\": user_query})\n",
        "    st.chat_message(\"user\").write(user_query)\n",
        "\n",
        "    with st.chat_message(\"assistant\"):\n",
        "        st_cb = StreamlitCallbackHandler(st.container())\n",
        "        response = agent.invoke(user_query, callbacks=[st_cb])\n",
        "        st.session_state.messages.append({\"role\": \"assistant\", \"content\": response})\n",
        "        st.write(response)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jon3YtelKv82",
        "outputId": "27af8d24-6b74-4089-e651-5874569f29f9"
      },
      "execution_count": 76,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overwriting streaming_app.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 77,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nQz0WaTTcTQK",
        "outputId": "0db492f9-5697-4e27-8cd4-e43f687f1283"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "35.221.32.163\n",
            "Copy the IP above into the webpage that opens below\n",
            "you also need to allow the port access to the database\n",
            "\u001b[K\u001b[?25hnpx: installed 22 in 2.194s\n",
            "your url is: https://tasty-shoes-say.loca.lt\n",
            "^C\n"
          ]
        }
      ],
      "source": [
        "!streamlit run streaming_app.py &>/content/logs.txt &\n",
        "!curl ipv4.icanhazip.com\n",
        "!echo \"Copy the IP above into the webpage that opens below\"\n",
        "!echo \"you also need to allow the port access to the database\"\n",
        "!npx localtunnel --port 8501\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Tx0TRFdPcAPO"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.6"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}