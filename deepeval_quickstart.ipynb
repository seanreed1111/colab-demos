{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "d6e6c782554741a38342cae5167aae29": {
          "model_module": "@jupyter-widgets/output",
          "model_name": "OutputModel",
          "model_module_version": "1.0.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/output",
            "_model_module_version": "1.0.0",
            "_model_name": "OutputModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/output",
            "_view_module_version": "1.0.0",
            "_view_name": "OutputView",
            "layout": "IPY_MODEL_f5201a7541fd41deb9999ed60423c5f7",
            "msg_id": "",
            "outputs": [
              {
                "output_type": "display_data",
                "data": {
                  "text/plain": "\u001b[38;2;106;0;255mâ ¼\u001b[0m âœ¨ You're running DeepEval's latest \u001b[38;2;106;0;255mAnswer Relevancy Metric\u001b[0m! \u001b[38;2;55;65;81m(using gpt-4o, strict=False, async_mode=True)...\u001b[0m\n",
                  "text/html": "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #6a00ff; text-decoration-color: #6a00ff\">â ¼</span> âœ¨ You're running DeepEval's latest <span style=\"color: #6a00ff; text-decoration-color: #6a00ff\">Answer Relevancy Metric</span>! <span style=\"color: #374151; text-decoration-color: #374151\">(using gpt-4o, strict=False, async_mode=True)...</span>\n</pre>\n"
                },
                "metadata": {}
              }
            ]
          }
        },
        "f5201a7541fd41deb9999ed60423c5f7": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "30fe19007b454d869acd6f3a993bd6cc": {
          "model_module": "@jupyter-widgets/output",
          "model_name": "OutputModel",
          "model_module_version": "1.0.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/output",
            "_model_module_version": "1.0.0",
            "_model_name": "OutputModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/output",
            "_view_module_version": "1.0.0",
            "_view_name": "OutputView",
            "layout": "IPY_MODEL_d4875fd0953c43f6ad84d89a2e0c31b3",
            "msg_id": "",
            "outputs": [
              {
                "output_type": "display_data",
                "data": {
                  "text/plain": "\u001b[38;2;106;0;255mâ ‹\u001b[0m âœ¨ You're running DeepEval's latest \u001b[38;2;106;0;255mAnswer Relevancy Metric\u001b[0m! \u001b[38;2;55;65;81m(using gpt-4o, strict=False, async_mode=True)...\u001b[0m\n",
                  "text/html": "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #6a00ff; text-decoration-color: #6a00ff\">â ‹</span> âœ¨ You're running DeepEval's latest <span style=\"color: #6a00ff; text-decoration-color: #6a00ff\">Answer Relevancy Metric</span>! <span style=\"color: #374151; text-decoration-color: #374151\">(using gpt-4o, strict=False, async_mode=True)...</span>\n</pre>\n"
                },
                "metadata": {}
              }
            ]
          }
        },
        "d4875fd0953c43f6ad84d89a2e0c31b3": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1de424c5f70b468990adaa131dc6d2e9": {
          "model_module": "@jupyter-widgets/output",
          "model_name": "OutputModel",
          "model_module_version": "1.0.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/output",
            "_model_module_version": "1.0.0",
            "_model_name": "OutputModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/output",
            "_view_module_version": "1.0.0",
            "_view_name": "OutputView",
            "layout": "IPY_MODEL_0ea7cfa01c2e4193bb5497d132fb19f2",
            "msg_id": "",
            "outputs": [
              {
                "output_type": "display_data",
                "data": {
                  "text/plain": "\u001b[38;2;106;0;255mâ ¦\u001b[0m âœ¨ You're running DeepEval's latest \u001b[38;2;106;0;255mAnswer Relevancy Metric\u001b[0m! \u001b[38;2;55;65;81m(using gpt-4o, strict=False, async_mode=True)...\u001b[0m\n",
                  "text/html": "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #6a00ff; text-decoration-color: #6a00ff\">â ¦</span> âœ¨ You're running DeepEval's latest <span style=\"color: #6a00ff; text-decoration-color: #6a00ff\">Answer Relevancy Metric</span>! <span style=\"color: #374151; text-decoration-color: #374151\">(using gpt-4o, strict=False, async_mode=True)...</span>\n</pre>\n"
                },
                "metadata": {}
              }
            ]
          }
        },
        "0ea7cfa01c2e4193bb5497d132fb19f2": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "145de871aa03431baae9eccd3dd40d06": {
          "model_module": "@jupyter-widgets/output",
          "model_name": "OutputModel",
          "model_module_version": "1.0.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/output",
            "_model_module_version": "1.0.0",
            "_model_name": "OutputModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/output",
            "_view_module_version": "1.0.0",
            "_view_name": "OutputView",
            "layout": "IPY_MODEL_b41691c799894f3291d19fe4f5aa3870",
            "msg_id": "",
            "outputs": [
              {
                "output_type": "display_data",
                "data": {
                  "text/plain": "\u001b[38;2;106;0;255mâ §\u001b[0m âœ¨ You're running DeepEval's latest \u001b[38;2;106;0;255mAnswer Relevancy Metric\u001b[0m! \u001b[38;2;55;65;81m(using gpt-4o, strict=False, async_mode=True)...\u001b[0m\n",
                  "text/html": "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #6a00ff; text-decoration-color: #6a00ff\">â §</span> âœ¨ You're running DeepEval's latest <span style=\"color: #6a00ff; text-decoration-color: #6a00ff\">Answer Relevancy Metric</span>! <span style=\"color: #374151; text-decoration-color: #374151\">(using gpt-4o, strict=False, async_mode=True)...</span>\n</pre>\n"
                },
                "metadata": {}
              }
            ]
          }
        },
        "b41691c799894f3291d19fe4f5aa3870": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/seanreed1111/colab-demos/blob/master/deepeval_quickstart.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# ğŸ¤— Welcome to DeepEval!\n",
        "\n",
        "Thanks for trying us out, we're here to provide you with the best LLM evaluation experience you can dream of ğŸ˜Š any questions or concerns you may have, [come talk to us on discord,](https://discord.com/invite/a3K9c8GRGt) we're always here to help!\n",
        "\n",
        "# What is DeepEval?\n",
        "\n",
        "DeepEval is the evaluation framework for LLMs. It takes the latest research (eg., G-Eval, SelfCheckGPT, RAGAS) in LLM evaluation and implement it as metrics for anyone to easily plug and use.\n",
        "\n",
        "Our strength lies in the simplicity and ease of use, while being a full evaluation suite for LLMs. Hope you enjoy trying us out!\n",
        "\n",
        "# Installation\n",
        "\n",
        "Install deepeval, you can ignore the warnings at the end of the installation."
      ],
      "metadata": {
        "id": "bDgDprF_xbkS"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "hz58Byh2m60V",
        "outputId": "07f7ad73-d41d-4ea1-ebdb-680dd85c0c2a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting deepeval\n",
            "  Downloading deepeval-0.21.45-py3-none-any.whl (244 kB)\n",
            "\u001b[?25l     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m0.0/244.6 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[91mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[90mâ•º\u001b[0m\u001b[90mâ”â”â”â”â”â”\u001b[0m \u001b[32m204.8/244.6 kB\u001b[0m \u001b[31m6.0 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m244.6/244.6 kB\u001b[0m \u001b[31m4.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from deepeval) (2.31.0)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from deepeval) (4.66.4)\n",
            "Requirement already satisfied: pytest in /usr/local/lib/python3.10/dist-packages (from deepeval) (7.4.4)\n",
            "Requirement already satisfied: tabulate in /usr/local/lib/python3.10/dist-packages (from deepeval) (0.9.0)\n",
            "Requirement already satisfied: typer in /usr/local/lib/python3.10/dist-packages (from deepeval) (0.9.4)\n",
            "Requirement already satisfied: rich in /usr/local/lib/python3.10/dist-packages (from deepeval) (13.7.1)\n",
            "Collecting protobuf==4.25.1 (from deepeval)\n",
            "  Downloading protobuf-4.25.1-cp37-abi3-manylinux2014_x86_64.whl (294 kB)\n",
            "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m294.6/294.6 kB\u001b[0m \u001b[31m4.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: pydantic in /usr/local/lib/python3.10/dist-packages (from deepeval) (2.7.1)\n",
            "Collecting sentry-sdk (from deepeval)\n",
            "  Downloading sentry_sdk-2.3.1-py2.py3-none-any.whl (289 kB)\n",
            "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m289.0/289.0 kB\u001b[0m \u001b[31m6.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting pytest-repeat (from deepeval)\n",
            "  Downloading pytest_repeat-0.9.3-py3-none-any.whl (4.2 kB)\n",
            "Collecting pytest-xdist (from deepeval)\n",
            "  Downloading pytest_xdist-3.6.1-py3-none-any.whl (46 kB)\n",
            "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m46.1/46.1 kB\u001b[0m \u001b[31m2.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting portalocker (from deepeval)\n",
            "  Downloading portalocker-2.8.2-py3-none-any.whl (17 kB)\n",
            "Collecting langchain (from deepeval)\n",
            "  Downloading langchain-0.2.0-py3-none-any.whl (973 kB)\n",
            "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m973.7/973.7 kB\u001b[0m \u001b[31m34.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting langchain-core (from deepeval)\n",
            "  Downloading langchain_core-0.2.1-py3-none-any.whl (308 kB)\n",
            "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m308.5/308.5 kB\u001b[0m \u001b[31m19.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting langchain-openai (from deepeval)\n",
            "  Downloading langchain_openai-0.1.7-py3-none-any.whl (34 kB)\n",
            "Collecting ragas (from deepeval)\n",
            "  Downloading ragas-0.1.8-py3-none-any.whl (84 kB)\n",
            "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m84.1/84.1 kB\u001b[0m \u001b[31m6.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting docx2txt~=0.8 (from deepeval)\n",
            "  Downloading docx2txt-0.8.tar.gz (2.8 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: importlib-metadata>=6.0.2 in /usr/local/lib/python3.10/dist-packages (from deepeval) (7.1.0)\n",
            "Collecting tenacity~=8.2.3 (from deepeval)\n",
            "  Downloading tenacity-8.2.3-py3-none-any.whl (24 kB)\n",
            "Collecting opentelemetry-api<2.0.0,>=1.14.0 (from deepeval)\n",
            "  Downloading opentelemetry_api-1.24.0-py3-none-any.whl (60 kB)\n",
            "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m60.1/60.1 kB\u001b[0m \u001b[31m5.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting opentelemetry-sdk<2.0.0,>=1.14.0 (from deepeval)\n",
            "  Downloading opentelemetry_sdk-1.24.0-py3-none-any.whl (106 kB)\n",
            "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m106.1/106.1 kB\u001b[0m \u001b[31m7.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting opentelemetry-exporter-otlp-proto-grpc<2.0.0,>=1.24.0 (from deepeval)\n",
            "  Downloading opentelemetry_exporter_otlp_proto_grpc-1.24.0-py3-none-any.whl (18 kB)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.10/dist-packages (from importlib-metadata>=6.0.2->deepeval) (3.18.2)\n",
            "Collecting deprecated>=1.2.6 (from opentelemetry-api<2.0.0,>=1.14.0->deepeval)\n",
            "  Downloading Deprecated-1.2.14-py2.py3-none-any.whl (9.6 kB)\n",
            "Collecting importlib-metadata>=6.0.2 (from deepeval)\n",
            "  Downloading importlib_metadata-7.0.0-py3-none-any.whl (23 kB)\n",
            "Requirement already satisfied: googleapis-common-protos~=1.52 in /usr/local/lib/python3.10/dist-packages (from opentelemetry-exporter-otlp-proto-grpc<2.0.0,>=1.24.0->deepeval) (1.63.0)\n",
            "Requirement already satisfied: grpcio<2.0.0,>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from opentelemetry-exporter-otlp-proto-grpc<2.0.0,>=1.24.0->deepeval) (1.63.0)\n",
            "Collecting opentelemetry-exporter-otlp-proto-common==1.24.0 (from opentelemetry-exporter-otlp-proto-grpc<2.0.0,>=1.24.0->deepeval)\n",
            "  Downloading opentelemetry_exporter_otlp_proto_common-1.24.0-py3-none-any.whl (17 kB)\n",
            "Collecting opentelemetry-proto==1.24.0 (from opentelemetry-exporter-otlp-proto-grpc<2.0.0,>=1.24.0->deepeval)\n",
            "  Downloading opentelemetry_proto-1.24.0-py3-none-any.whl (50 kB)\n",
            "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m50.8/50.8 kB\u001b[0m \u001b[31m3.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting opentelemetry-semantic-conventions==0.45b0 (from opentelemetry-sdk<2.0.0,>=1.14.0->deepeval)\n",
            "  Downloading opentelemetry_semantic_conventions-0.45b0-py3-none-any.whl (36 kB)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4 in /usr/local/lib/python3.10/dist-packages (from opentelemetry-sdk<2.0.0,>=1.14.0->deepeval) (4.11.0)\n",
            "Requirement already satisfied: PyYAML>=5.3 in /usr/local/lib/python3.10/dist-packages (from langchain->deepeval) (6.0.1)\n",
            "Requirement already satisfied: SQLAlchemy<3,>=1.4 in /usr/local/lib/python3.10/dist-packages (from langchain->deepeval) (2.0.30)\n",
            "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /usr/local/lib/python3.10/dist-packages (from langchain->deepeval) (3.9.5)\n",
            "Requirement already satisfied: async-timeout<5.0.0,>=4.0.0 in /usr/local/lib/python3.10/dist-packages (from langchain->deepeval) (4.0.3)\n",
            "Collecting dataclasses-json<0.7,>=0.5.7 (from langchain->deepeval)\n",
            "  Downloading dataclasses_json-0.6.6-py3-none-any.whl (28 kB)\n",
            "Collecting langchain-text-splitters<0.3.0,>=0.2.0 (from langchain->deepeval)\n",
            "  Downloading langchain_text_splitters-0.2.0-py3-none-any.whl (23 kB)\n",
            "Collecting langsmith<0.2.0,>=0.1.17 (from langchain->deepeval)\n",
            "  Downloading langsmith-0.1.62-py3-none-any.whl (122 kB)\n",
            "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m122.3/122.3 kB\u001b[0m \u001b[31m9.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: numpy<2,>=1 in /usr/local/lib/python3.10/dist-packages (from langchain->deepeval) (1.25.2)\n",
            "Collecting jsonpatch<2.0,>=1.33 (from langchain-core->deepeval)\n",
            "  Downloading jsonpatch-1.33-py2.py3-none-any.whl (12 kB)\n",
            "Collecting packaging<24.0,>=23.2 (from langchain-core->deepeval)\n",
            "  Downloading packaging-23.2-py3-none-any.whl (53 kB)\n",
            "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m53.0/53.0 kB\u001b[0m \u001b[31m4.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: annotated-types>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from pydantic->deepeval) (0.6.0)\n",
            "Requirement already satisfied: pydantic-core==2.18.2 in /usr/local/lib/python3.10/dist-packages (from pydantic->deepeval) (2.18.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->deepeval) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->deepeval) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->deepeval) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->deepeval) (2024.2.2)\n",
            "Collecting openai<2.0.0,>=1.24.0 (from langchain-openai->deepeval)\n",
            "  Downloading openai-1.30.2-py3-none-any.whl (320 kB)\n",
            "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m320.7/320.7 kB\u001b[0m \u001b[31m17.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting tiktoken<1,>=0.7 (from langchain-openai->deepeval)\n",
            "  Downloading tiktoken-0.7.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.1 MB)\n",
            "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m18.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: iniconfig in /usr/local/lib/python3.10/dist-packages (from pytest->deepeval) (2.0.0)\n",
            "Requirement already satisfied: pluggy<2.0,>=0.12 in /usr/local/lib/python3.10/dist-packages (from pytest->deepeval) (1.5.0)\n",
            "Requirement already satisfied: exceptiongroup>=1.0.0rc8 in /usr/local/lib/python3.10/dist-packages (from pytest->deepeval) (1.2.1)\n",
            "Requirement already satisfied: tomli>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from pytest->deepeval) (2.0.1)\n",
            "Collecting execnet>=2.1 (from pytest-xdist->deepeval)\n",
            "  Downloading execnet-2.1.1-py3-none-any.whl (40 kB)\n",
            "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m40.6/40.6 kB\u001b[0m \u001b[31m2.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting datasets (from ragas->deepeval)\n",
            "  Downloading datasets-2.19.1-py3-none-any.whl (542 kB)\n",
            "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m542.0/542.0 kB\u001b[0m \u001b[31m27.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting langchain-community (from ragas->deepeval)\n",
            "  Downloading langchain_community-0.2.0-py3-none-any.whl (2.1 MB)\n",
            "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m2.1/2.1 MB\u001b[0m \u001b[31m49.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting pysbd>=0.3.4 (from ragas->deepeval)\n",
            "  Downloading pysbd-0.3.4-py3-none-any.whl (71 kB)\n",
            "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m71.1/71.1 kB\u001b[0m \u001b[31m4.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: nest-asyncio in /usr/local/lib/python3.10/dist-packages (from ragas->deepeval) (1.6.0)\n",
            "Requirement already satisfied: appdirs in /usr/local/lib/python3.10/dist-packages (from ragas->deepeval) (1.4.4)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from rich->deepeval) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from rich->deepeval) (2.16.1)\n",
            "Requirement already satisfied: click<9.0.0,>=7.1.1 in /usr/local/lib/python3.10/dist-packages (from typer->deepeval) (8.1.7)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain->deepeval) (1.3.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain->deepeval) (23.2.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain->deepeval) (1.4.1)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain->deepeval) (6.0.5)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain->deepeval) (1.9.4)\n",
            "Collecting marshmallow<4.0.0,>=3.18.0 (from dataclasses-json<0.7,>=0.5.7->langchain->deepeval)\n",
            "  Downloading marshmallow-3.21.2-py3-none-any.whl (49 kB)\n",
            "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m49.3/49.3 kB\u001b[0m \u001b[31m2.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting typing-inspect<1,>=0.4.0 (from dataclasses-json<0.7,>=0.5.7->langchain->deepeval)\n",
            "  Downloading typing_inspect-0.9.0-py3-none-any.whl (8.8 kB)\n",
            "Requirement already satisfied: wrapt<2,>=1.10 in /usr/local/lib/python3.10/dist-packages (from deprecated>=1.2.6->opentelemetry-api<2.0.0,>=1.14.0->deepeval) (1.14.1)\n",
            "Collecting jsonpointer>=1.9 (from jsonpatch<2.0,>=1.33->langchain-core->deepeval)\n",
            "  Downloading jsonpointer-2.4-py2.py3-none-any.whl (7.8 kB)\n",
            "Collecting orjson<4.0.0,>=3.9.14 (from langsmith<0.2.0,>=0.1.17->langchain->deepeval)\n",
            "  Downloading orjson-3.10.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (142 kB)\n",
            "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m142.5/142.5 kB\u001b[0m \u001b[31m5.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py>=2.2.0->rich->deepeval) (0.1.2)\n",
            "Requirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.10/dist-packages (from openai<2.0.0,>=1.24.0->langchain-openai->deepeval) (3.7.1)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/lib/python3/dist-packages (from openai<2.0.0,>=1.24.0->langchain-openai->deepeval) (1.7.0)\n",
            "Collecting httpx<1,>=0.23.0 (from openai<2.0.0,>=1.24.0->langchain-openai->deepeval)\n",
            "  Downloading httpx-0.27.0-py3-none-any.whl (75 kB)\n",
            "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m75.6/75.6 kB\u001b[0m \u001b[31m6.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: sniffio in /usr/local/lib/python3.10/dist-packages (from openai<2.0.0,>=1.24.0->langchain-openai->deepeval) (1.3.1)\n",
            "Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.10/dist-packages (from SQLAlchemy<3,>=1.4->langchain->deepeval) (3.0.3)\n",
            "Requirement already satisfied: regex>=2022.1.18 in /usr/local/lib/python3.10/dist-packages (from tiktoken<1,>=0.7->langchain-openai->deepeval) (2023.12.25)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from datasets->ragas->deepeval) (3.14.0)\n",
            "Requirement already satisfied: pyarrow>=12.0.0 in /usr/local/lib/python3.10/dist-packages (from datasets->ragas->deepeval) (14.0.2)\n",
            "Requirement already satisfied: pyarrow-hotfix in /usr/local/lib/python3.10/dist-packages (from datasets->ragas->deepeval) (0.6)\n",
            "Collecting dill<0.3.9,>=0.3.0 (from datasets->ragas->deepeval)\n",
            "  Downloading dill-0.3.8-py3-none-any.whl (116 kB)\n",
            "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m116.3/116.3 kB\u001b[0m \u001b[31m10.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from datasets->ragas->deepeval) (2.0.3)\n",
            "Collecting xxhash (from datasets->ragas->deepeval)\n",
            "  Downloading xxhash-3.4.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (194 kB)\n",
            "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m194.1/194.1 kB\u001b[0m \u001b[31m10.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting multiprocess (from datasets->ragas->deepeval)\n",
            "  Downloading multiprocess-0.70.16-py310-none-any.whl (134 kB)\n",
            "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m134.8/134.8 kB\u001b[0m \u001b[31m12.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: fsspec[http]<=2024.3.1,>=2023.1.0 in /usr/local/lib/python3.10/dist-packages (from datasets->ragas->deepeval) (2023.6.0)\n",
            "Requirement already satisfied: huggingface-hub>=0.21.2 in /usr/local/lib/python3.10/dist-packages (from datasets->ragas->deepeval) (0.23.0)\n",
            "Collecting httpcore==1.* (from httpx<1,>=0.23.0->openai<2.0.0,>=1.24.0->langchain-openai->deepeval)\n",
            "  Downloading httpcore-1.0.5-py3-none-any.whl (77 kB)\n",
            "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m77.9/77.9 kB\u001b[0m \u001b[31m7.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting h11<0.15,>=0.13 (from httpcore==1.*->httpx<1,>=0.23.0->openai<2.0.0,>=1.24.0->langchain-openai->deepeval)\n",
            "  Downloading h11-0.14.0-py3-none-any.whl (58 kB)\n",
            "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m58.3/58.3 kB\u001b[0m \u001b[31m4.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting mypy-extensions>=0.3.0 (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.5.7->langchain->deepeval)\n",
            "  Downloading mypy_extensions-1.0.0-py3-none-any.whl (4.7 kB)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets->ragas->deepeval) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets->ragas->deepeval) (2023.4)\n",
            "Requirement already satisfied: tzdata>=2022.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets->ragas->deepeval) (2024.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->pandas->datasets->ragas->deepeval) (1.16.0)\n",
            "Building wheels for collected packages: docx2txt\n",
            "  Building wheel for docx2txt (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for docx2txt: filename=docx2txt-0.8-py3-none-any.whl size=3960 sha256=033d645a37de8161b7ace55bb5de811b0f749cf0b998b073f5885c957b8eb1c7\n",
            "  Stored in directory: /root/.cache/pip/wheels/22/58/cf/093d0a6c3ecfdfc5f6ddd5524043b88e59a9a199cb02352966\n",
            "Successfully built docx2txt\n",
            "Installing collected packages: docx2txt, xxhash, tenacity, sentry-sdk, pysbd, protobuf, portalocker, packaging, orjson, opentelemetry-semantic-conventions, mypy-extensions, jsonpointer, importlib-metadata, h11, execnet, dill, deprecated, typing-inspect, tiktoken, opentelemetry-proto, opentelemetry-api, multiprocess, marshmallow, jsonpatch, httpcore, pytest-xdist, pytest-repeat, opentelemetry-sdk, opentelemetry-exporter-otlp-proto-common, langsmith, httpx, dataclasses-json, opentelemetry-exporter-otlp-proto-grpc, openai, langchain-core, datasets, langchain-text-splitters, langchain-openai, langchain, langchain-community, ragas, deepeval\n",
            "  Attempting uninstall: tenacity\n",
            "    Found existing installation: tenacity 8.3.0\n",
            "    Uninstalling tenacity-8.3.0:\n",
            "      Successfully uninstalled tenacity-8.3.0\n",
            "  Attempting uninstall: protobuf\n",
            "    Found existing installation: protobuf 3.20.3\n",
            "    Uninstalling protobuf-3.20.3:\n",
            "      Successfully uninstalled protobuf-3.20.3\n",
            "  Attempting uninstall: packaging\n",
            "    Found existing installation: packaging 24.0\n",
            "    Uninstalling packaging-24.0:\n",
            "      Successfully uninstalled packaging-24.0\n",
            "  Attempting uninstall: importlib-metadata\n",
            "    Found existing installation: importlib_metadata 7.1.0\n",
            "    Uninstalling importlib_metadata-7.1.0:\n",
            "      Successfully uninstalled importlib_metadata-7.1.0\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "tensorflow-metadata 1.15.0 requires protobuf<4.21,>=3.20.3; python_version < \"3.11\", but you have protobuf 4.25.1 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed dataclasses-json-0.6.6 datasets-2.19.1 deepeval-0.21.45 deprecated-1.2.14 dill-0.3.8 docx2txt-0.8 execnet-2.1.1 h11-0.14.0 httpcore-1.0.5 httpx-0.27.0 importlib-metadata-7.0.0 jsonpatch-1.33 jsonpointer-2.4 langchain-0.2.0 langchain-community-0.2.0 langchain-core-0.2.1 langchain-openai-0.1.7 langchain-text-splitters-0.2.0 langsmith-0.1.62 marshmallow-3.21.2 multiprocess-0.70.16 mypy-extensions-1.0.0 openai-1.30.2 opentelemetry-api-1.24.0 opentelemetry-exporter-otlp-proto-common-1.24.0 opentelemetry-exporter-otlp-proto-grpc-1.24.0 opentelemetry-proto-1.24.0 opentelemetry-sdk-1.24.0 opentelemetry-semantic-conventions-0.45b0 orjson-3.10.3 packaging-23.2 portalocker-2.8.2 protobuf-4.25.1 pysbd-0.3.4 pytest-repeat-0.9.3 pytest-xdist-3.6.1 ragas-0.1.8 sentry-sdk-2.3.1 tenacity-8.2.3 tiktoken-0.7.0 typing-inspect-0.9.0 xxhash-3.4.1\n"
          ]
        }
      ],
      "source": [
        "!pip install -U deepeval"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "^^ Please ignore the warnings after installation, but if you're concerned please run `!pip install cohere` as well."
      ],
      "metadata": {
        "id": "8weaJmIDr1PF"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Login (recommended step)\n",
        "\n",
        "Login to Confident AI to log evaluation results on the cloud. Later, you can use Confident AI to centralize evaluation datasets, perform real-time evaluations in production, and much more."
      ],
      "metadata": {
        "id": "FMwb2vPYoA2Y"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!deepeval login --confident-api-key your-api-key"
      ],
      "metadata": {
        "id": "E1Xh8ybXn7dJ",
        "outputId": "d31eb959-7bb0-4665-ab4d-7ddb28fb915e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Congratulations! Login successful ğŸ™Œ \n",
            "If you are new to DeepEval, follow our quickstart tutorial here: \n",
            "\u001b]8;id=430122;https://docs.confident-ai.com/docs/getting-started\u001b\\\u001b[1;4;94mhttps://docs.confident-ai.com/docs/getting-started\u001b[0m\u001b]8;;\u001b\\\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        " # ğŸ˜‡ Create Your First Test Case\n",
        "\n",
        " A test case in `deepeval` mimics a user interaction with your LLM (application)Here:\n",
        " - `input` is what a user would input\n",
        " - `actual_output` is the output of yoru LLM (application)\n",
        " - `retrieval_context` is the retrieved context in your RAG pipeline.\n",
        "\n",
        "Note that only RAG metrics require `retrieval_context` when creating a test case. Visit the [test cases section in our docs](https://docs.confident-ai.com/docs/evaluation-test-cases) to learn about how a test case work in `deepeval`."
      ],
      "metadata": {
        "id": "MoyW1ntQoQbv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from deepeval.test_case import LLMTestCase\n",
        "\n",
        "test_case = LLMTestCase(\n",
        "  input=\"What if these shoes don't fit?\",\n",
        "  # Replace this with the actual output of your LLM application\n",
        "  actual_output=\"We offer a 30-day full refund at no extra cost.\",\n",
        "  # Replace this with the retrieval context (in the RAG pipeline) of your LLM application\n",
        "  retrieval_context=[\"All customers are eligible for a 30 day full refund at no extra cost.\"]\n",
        ")"
      ],
      "metadata": {
        "id": "nGjEshHFm8tD"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# ğŸ¤— Create Your First Metric\n",
        "\n",
        "- A metric in `deepeval` evaluates based on the values of the parameters in a particular test case.\n",
        "- `deepeval` incorporates the latest research into its metrics implementation so you don't have to.\n",
        "\n",
        "## Set OpenAI API Key\n",
        "\n",
        "Most of `deepeval`'s metrics are evaluated using LLMs. To begin, set your `OPENAI_API_KEY` below (IMPORTANT: don't include quotation \"\" marks!)"
      ],
      "metadata": {
        "id": "xwSlhH0KpGk-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%env OPENAI_API_KEY="
      ],
      "metadata": {
        "id": "12hny5hmtt0K"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%env OPENAI_API_KEY=your-api-key"
      ],
      "metadata": {
        "id": "MMwsf9mfsZWU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "(Note that you don't have to use OpenAI, although we highly highly highly recommend it, since evaluation requires a high level of reasoning. That being said, if you want to use a custom model like Azure OpenAI, visit the [metrics section in our docs](https://docs.confident-ai.com/docs/metrics-introduction#using-a-custom-llm))\n",
        "\n",
        "\n",
        "## Create Your Metric\n",
        "\n",
        "In this example, we create an `AnswerRelevancyMetric`, which measures the answer relevancy of a RAG based LLM application. Not all metrics are RAG metrics. For a list of full metrics and an explanation for each, visit [the metrics section in our docs](https://docs.confident-ai.com/docs/metrics-introduction)"
      ],
      "metadata": {
        "id": "cksQJRtrskG3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from deepeval.metrics import AnswerRelevancyMetric\n",
        "\n",
        "answer_relevancy_metric = AnswerRelevancyMetric(threshold=0.5)"
      ],
      "metadata": {
        "id": "X9HpXp6sngFu"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# ğŸš€ Run Your First Evaluation\n",
        "\n",
        "With a test case and metric ready, you can start using our `evaluate()` function to evaluate your LLM (application).\n",
        "\n",
        "The `evaluate()` function accepts a list of test cases, and a list of metrics. Under the hood, it evaluates each individual test case using the list of provided metrics. A test case only passess if all the metrics are passing. For more information, including how to use our Pytest integration for evaluation, visit the evaluation [section in our docs.](https://docs.confident-ai.com/docs/evaluation-introduction)"
      ],
      "metadata": {
        "id": "-v2tKr8Yp8Ry"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from deepeval import evaluate\n",
        "\n",
        "evaluate([test_case], [answer_relevancy_metric])"
      ],
      "metadata": {
        "id": "C0yBxUBHnzWF",
        "outputId": "212b4596-71b6-416a-efc8-2a20a605f168",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 630,
          "referenced_widgets": [
            "d6e6c782554741a38342cae5167aae29",
            "f5201a7541fd41deb9999ed60423c5f7"
          ]
        }
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Output()"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "d6e6c782554741a38342cae5167aae29"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Evaluating test cases...\n",
            "Event loop is already running. Applying nest_asyncio patch to allow async execution...\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/portalocker/utils.py:218: UserWarning: timeout has no effect in blocking mode\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "======================================================================\n",
            "\n",
            "Metrics Summary\n",
            "\n",
            "  - âœ… Answer Relevancy (score: 1.0, threshold: 0.5, strict: False, evaluation model: gpt-4o, reason: The score is 1.00 because the answer is perfectly relevant to the question, providing a clear and direct response without any irrelevant statements. Great job!, error: None)\n",
            "\n",
            "For test case:\n",
            "\n",
            "  - input: What if these shoes don't fit?\n",
            "  - actual output: We offer a 30-day full refund at no extra cost.\n",
            "  - expected output: None\n",
            "  - context: None\n",
            "  - retrieval context: ['All customers are eligible for a 30 day full refund at no extra cost.']\n",
            "\n",
            "======================================================================\n",
            "\n",
            "Overall Metric Pass Rates\n",
            "\n",
            "AnswerRelevancyMetric: 100.00% pass rate\n",
            "\n",
            "======================================================================\n",
            "\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "âœ… Tests finished! View results on \n",
              "\u001b]8;id=653725;https://app.confident-ai.com/project/clwjavtlz0022js0doi80sojq/unit-tests/clwjb9bc00009l40cnx5mukg0/test-cases\u001b\\\u001b[4;94mhttps://app.confident-ai.com/project/clwjavtlz0022js0doi80sojq/unit-tests/clwjb9bc00009l40cnx5mukg0/test-cases\u001b[0m\u001b]8;;\u001b\\\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">âœ… Tests finished! View results on \n",
              "<a href=\"https://app.confident-ai.com/project/clwjavtlz0022js0doi80sojq/unit-tests/clwjb9bc00009l40cnx5mukg0/test-cases\" target=\"_blank\"><span style=\"color: #0000ff; text-decoration-color: #0000ff; text-decoration: underline\">https://app.confident-ai.com/project/clwjavtlz0022js0doi80sojq/unit-tests/clwjb9bc00009l40cnx5mukg0/test-cases</span></a>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[TestResult(success=True, metrics=[<deepeval.metrics.answer_relevancy.answer_relevancy.AnswerRelevancyMetric object at 0x7bf2ad2e5e10>], input=\"What if these shoes don't fit?\", actual_output='We offer a 30-day full refund at no extra cost.', expected_output=None, context=None, retrieval_context=['All customers are eligible for a 30 day full refund at no extra cost.'])]"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Using Standalone Metrics\n",
        "\n",
        "`deepeval` offers a simple way for anyone to plug and use our metrics. This is especially useful if you're looking to build your own evaluation pipelines. Using the previous example:"
      ],
      "metadata": {
        "id": "hhU0L9uWrWk1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from deepeval.test_case import LLMTestCase\n",
        "from deepeval.metrics import AnswerRelevancyMetric\n",
        "\n",
        "\n",
        "test_case = LLMTestCase(\n",
        "  input=\"What if these shoes don't fit?\",\n",
        "  # Replace this with the actual output of your LLM application\n",
        "  actual_output=\"We offer a 30-day full refund at no extra cost.\",\n",
        "  # Replace this with the retrieval context (in the RAG pipeline) of your LLM application\n",
        "  retrieval_context=[\"All customers are eligible for a 30 day full refund at no extra cost.\"]\n",
        ")\n",
        "answer_relevancy_metric = AnswerRelevancyMetric(threshold=0.5)\n",
        "\n",
        "answer_relevancy_metric.measure(test_case)\n",
        "print(answer_relevancy_metric.score)\n",
        "print(answer_relevancy_metric.reason)"
      ],
      "metadata": {
        "id": "EaWouoOUrkgj",
        "outputId": "01a5c542-8af3-47b6-acec-4eba8f0e22dc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 89,
          "referenced_widgets": [
            "30fe19007b454d869acd6f3a993bd6cc",
            "d4875fd0953c43f6ad84d89a2e0c31b3"
          ]
        }
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Output()"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "30fe19007b454d869acd6f3a993bd6cc"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Event loop is already running. Applying nest_asyncio patch to allow async execution...\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Event loop is already running. Applying nest_asyncio patch to allow async execution...\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1.0\n",
            "The score is 1.00 because the response is completely relevant and directly addresses your concern about the shoes not fitting. Great job!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Create Your First Evaluation Dataset\n",
        "\n",
        "An evaluation dataset in `deepeval` is a collection of test cases.\n",
        "\n",
        "It offers a rich set of features for you to manipulate evaluation data. For more information, visit the [dataset section in our docs.](https://docs.confident-ai.com/docs/evaluation-datasets)"
      ],
      "metadata": {
        "id": "QPh31S8QuCam"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from deepeval import evaluate\n",
        "from deepeval.dataset import EvaluationDataset\n",
        "from deepeval.test_case import LLMTestCase\n",
        "from deepeval.metrics import AnswerRelevancyMetric\n",
        "\n",
        "test_case_1 = LLMTestCase(\n",
        "  input=\"What if these shoes don't fit?\",\n",
        "  actual_output=\"We offer a 30-day full refund at no extra cost.\",\n",
        "  retrieval_context=[\"All customers are eligible for a 30 day full refund at no extra cost.\"]\n",
        ")\n",
        "test_case_2 = LLMTestCase(\n",
        "  input=\"What should you do if there's a fire?\",\n",
        "  actual_output=\"Drop and roll.\",\n",
        "  retrieval_context=[\"Don't use the elevator in the case of a fire.\"]\n",
        ")\n",
        "answer_relevancy_metric = AnswerRelevancyMetric(threshold=0.5)\n",
        "\n",
        "dataset = EvaluationDataset(test_cases=[test_case_1, test_case_2])\n",
        "\n",
        "# Same as before, using the evaluate function\n",
        "evaluate(dataset, [answer_relevancy_metric])\n",
        "\n",
        "# Or, use the evaluate method directly, they're exactly the same\n",
        "# dataset.evaluate([answer_relevancy_metric])"
      ],
      "metadata": {
        "id": "MxFMHQZOucxs",
        "outputId": "d4a33932-2895-40ff-f123-8f187325fbd6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 989,
          "referenced_widgets": [
            "1de424c5f70b468990adaa131dc6d2e9",
            "0ea7cfa01c2e4193bb5497d132fb19f2",
            "145de871aa03431baae9eccd3dd40d06",
            "b41691c799894f3291d19fe4f5aa3870"
          ]
        }
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Output()"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "1de424c5f70b468990adaa131dc6d2e9"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Evaluating test cases...\n",
            "Event loop is already running. Applying nest_asyncio patch to allow async execution...\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Output()"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "145de871aa03431baae9eccd3dd40d06"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/portalocker/utils.py:218: UserWarning: timeout has no effect in blocking mode\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/portalocker/utils.py:218: UserWarning: timeout has no effect in blocking mode\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "======================================================================\n",
            "\n",
            "Metrics Summary\n",
            "\n",
            "  - âœ… Answer Relevancy (score: 1.0, threshold: 0.5, strict: False, evaluation model: gpt-4o, reason: The score is 1.00 because the response directly addresses the question about the shoes not fitting without including any irrelevant information. Great job keeping it on point!, error: None)\n",
            "\n",
            "For test case:\n",
            "\n",
            "  - input: What if these shoes don't fit?\n",
            "  - actual output: We offer a 30-day full refund at no extra cost.\n",
            "  - expected output: None\n",
            "  - context: None\n",
            "  - retrieval context: ['All customers are eligible for a 30 day full refund at no extra cost.']\n",
            "\n",
            "======================================================================\n",
            "\n",
            "Metrics Summary\n",
            "\n",
            "  - âœ… Answer Relevancy (score: 1.0, threshold: 0.5, strict: False, evaluation model: gpt-4o, reason: The score is 1.00 because the response perfectly addresses the question without any irrelevant information. Fantastic job!, error: None)\n",
            "\n",
            "For test case:\n",
            "\n",
            "  - input: What should you do if there's a fire?\n",
            "  - actual output: Drop and roll.\n",
            "  - expected output: None\n",
            "  - context: None\n",
            "  - retrieval context: [\"Don't use the elevator in the case of a fire.\"]\n",
            "\n",
            "======================================================================\n",
            "\n",
            "Overall Metric Pass Rates\n",
            "\n",
            "AnswerRelevancyMetric: 100.00% pass rate\n",
            "\n",
            "======================================================================\n",
            "\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "âœ… Tests finished! View results on \n",
              "\u001b]8;id=70995;https://app.confident-ai.com/project/clwjavtlz0022js0doi80sojq/unit-tests/clwjbvps4000zl40cweeljw21/test-cases\u001b\\\u001b[4;94mhttps://app.confident-ai.com/project/clwjavtlz0022js0doi80sojq/unit-tests/clwjbvps4000zl40cweeljw21/test-cases\u001b[0m\u001b]8;;\u001b\\\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">âœ… Tests finished! View results on \n",
              "<a href=\"https://app.confident-ai.com/project/clwjavtlz0022js0doi80sojq/unit-tests/clwjbvps4000zl40cweeljw21/test-cases\" target=\"_blank\"><span style=\"color: #0000ff; text-decoration-color: #0000ff; text-decoration: underline\">https://app.confident-ai.com/project/clwjavtlz0022js0doi80sojq/unit-tests/clwjbvps4000zl40cweeljw21/test-cases</span></a>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[TestResult(success=True, metrics=[<deepeval.metrics.answer_relevancy.answer_relevancy.AnswerRelevancyMetric object at 0x7bf2ad213cd0>], input=\"What if these shoes don't fit?\", actual_output='We offer a 30-day full refund at no extra cost.', expected_output=None, context=None, retrieval_context=['All customers are eligible for a 30 day full refund at no extra cost.']),\n",
              " TestResult(success=True, metrics=[<deepeval.metrics.answer_relevancy.answer_relevancy.AnswerRelevancyMetric object at 0x7bf2ad2651b0>], input=\"What should you do if there's a fire?\", actual_output='Drop and roll.', expected_output=None, context=None, retrieval_context=[\"Don't use the elevator in the case of a fire.\"])]"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "_hmA0BWdx8Dr"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}