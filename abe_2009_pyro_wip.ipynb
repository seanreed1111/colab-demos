{
  "metadata": {
    "kernelspec": {
      "language": "python",
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "version": "3.6.4",
      "file_extension": ".py",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "name": "python",
      "mimetype": "text/x-python"
    },
    "colab": {
      "name": "abe_2009_pyro_wip.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    }
  },
  "nbformat_minor": 0,
  "nbformat": 4,
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/seanreed1111/colab-demos/blob/master/abe_2009_pyro_wip.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "see also: \n",
        "- \"COUNTING YOUR CUSTOMERS” ONE BY ONE: A Hierarchical Bayes Extension to the Pareto/NBD Model Abe 2009 http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.687.3554&rep=rep1&type=pdf\n",
        "\n",
        "- https://github.com/mplatzer/BTYDplus\n",
        "\n",
        "- Numpyro adventures in covariance https://colab.research.google.com/drive/1pQptn66Ir-Jesph-1CRf5OZ-TmaiZWH5#scrollTo=mDJFmLo8ZUKz\n"
      ],
      "metadata": {
        "id": "eQA5kIjjxpuy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# installlation required\n",
        "!pip install -q pyro-ppl=='1.8.0'\n"
      ],
      "metadata": {
        "id": "uY7dTQrGT7o2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f81928d7-1fa6-4700-c59b-3b37f4444a33"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[?25l\r\u001b[K     |▌                               | 10 kB 15.9 MB/s eta 0:00:01\r\u001b[K     |█                               | 20 kB 11.0 MB/s eta 0:00:01\r\u001b[K     |█▍                              | 30 kB 6.6 MB/s eta 0:00:01\r\u001b[K     |█▉                              | 40 kB 6.3 MB/s eta 0:00:01\r\u001b[K     |██▎                             | 51 kB 4.2 MB/s eta 0:00:01\r\u001b[K     |██▊                             | 61 kB 4.9 MB/s eta 0:00:01\r\u001b[K     |███▏                            | 71 kB 4.9 MB/s eta 0:00:01\r\u001b[K     |███▊                            | 81 kB 4.8 MB/s eta 0:00:01\r\u001b[K     |████▏                           | 92 kB 5.3 MB/s eta 0:00:01\r\u001b[K     |████▋                           | 102 kB 4.9 MB/s eta 0:00:01\r\u001b[K     |█████                           | 112 kB 4.9 MB/s eta 0:00:01\r\u001b[K     |█████▌                          | 122 kB 4.9 MB/s eta 0:00:01\r\u001b[K     |██████                          | 133 kB 4.9 MB/s eta 0:00:01\r\u001b[K     |██████▍                         | 143 kB 4.9 MB/s eta 0:00:01\r\u001b[K     |███████                         | 153 kB 4.9 MB/s eta 0:00:01\r\u001b[K     |███████▍                        | 163 kB 4.9 MB/s eta 0:00:01\r\u001b[K     |███████▉                        | 174 kB 4.9 MB/s eta 0:00:01\r\u001b[K     |████████▎                       | 184 kB 4.9 MB/s eta 0:00:01\r\u001b[K     |████████▊                       | 194 kB 4.9 MB/s eta 0:00:01\r\u001b[K     |█████████▏                      | 204 kB 4.9 MB/s eta 0:00:01\r\u001b[K     |█████████▋                      | 215 kB 4.9 MB/s eta 0:00:01\r\u001b[K     |██████████                      | 225 kB 4.9 MB/s eta 0:00:01\r\u001b[K     |██████████▋                     | 235 kB 4.9 MB/s eta 0:00:01\r\u001b[K     |███████████                     | 245 kB 4.9 MB/s eta 0:00:01\r\u001b[K     |███████████▌                    | 256 kB 4.9 MB/s eta 0:00:01\r\u001b[K     |████████████                    | 266 kB 4.9 MB/s eta 0:00:01\r\u001b[K     |████████████▍                   | 276 kB 4.9 MB/s eta 0:00:01\r\u001b[K     |████████████▉                   | 286 kB 4.9 MB/s eta 0:00:01\r\u001b[K     |█████████████▎                  | 296 kB 4.9 MB/s eta 0:00:01\r\u001b[K     |█████████████▉                  | 307 kB 4.9 MB/s eta 0:00:01\r\u001b[K     |██████████████▎                 | 317 kB 4.9 MB/s eta 0:00:01\r\u001b[K     |██████████████▊                 | 327 kB 4.9 MB/s eta 0:00:01\r\u001b[K     |███████████████▏                | 337 kB 4.9 MB/s eta 0:00:01\r\u001b[K     |███████████████▋                | 348 kB 4.9 MB/s eta 0:00:01\r\u001b[K     |████████████████                | 358 kB 4.9 MB/s eta 0:00:01\r\u001b[K     |████████████████▌               | 368 kB 4.9 MB/s eta 0:00:01\r\u001b[K     |█████████████████               | 378 kB 4.9 MB/s eta 0:00:01\r\u001b[K     |█████████████████▌              | 389 kB 4.9 MB/s eta 0:00:01\r\u001b[K     |██████████████████              | 399 kB 4.9 MB/s eta 0:00:01\r\u001b[K     |██████████████████▍             | 409 kB 4.9 MB/s eta 0:00:01\r\u001b[K     |██████████████████▉             | 419 kB 4.9 MB/s eta 0:00:01\r\u001b[K     |███████████████████▎            | 430 kB 4.9 MB/s eta 0:00:01\r\u001b[K     |███████████████████▊            | 440 kB 4.9 MB/s eta 0:00:01\r\u001b[K     |████████████████████▏           | 450 kB 4.9 MB/s eta 0:00:01\r\u001b[K     |████████████████████▊           | 460 kB 4.9 MB/s eta 0:00:01\r\u001b[K     |█████████████████████▏          | 471 kB 4.9 MB/s eta 0:00:01\r\u001b[K     |█████████████████████▋          | 481 kB 4.9 MB/s eta 0:00:01\r\u001b[K     |██████████████████████          | 491 kB 4.9 MB/s eta 0:00:01\r\u001b[K     |██████████████████████▌         | 501 kB 4.9 MB/s eta 0:00:01\r\u001b[K     |███████████████████████         | 512 kB 4.9 MB/s eta 0:00:01\r\u001b[K     |███████████████████████▍        | 522 kB 4.9 MB/s eta 0:00:01\r\u001b[K     |████████████████████████        | 532 kB 4.9 MB/s eta 0:00:01\r\u001b[K     |████████████████████████▍       | 542 kB 4.9 MB/s eta 0:00:01\r\u001b[K     |████████████████████████▉       | 552 kB 4.9 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▎      | 563 kB 4.9 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▊      | 573 kB 4.9 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▏     | 583 kB 4.9 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▋     | 593 kB 4.9 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████     | 604 kB 4.9 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▋    | 614 kB 4.9 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████    | 624 kB 4.9 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▌   | 634 kB 4.9 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████   | 645 kB 4.9 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▍  | 655 kB 4.9 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▉  | 665 kB 4.9 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▎ | 675 kB 4.9 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▉ | 686 kB 4.9 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▎| 696 kB 4.9 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▊| 706 kB 4.9 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 713 kB 4.9 MB/s \n",
            "\u001b[?25h"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "<a id = \"7\"></a><br>\n",
        "# LIBRARIES"
      ],
      "metadata": {
        "id": "FGj7ZXnYisy4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import datetime as dt\n",
        "import pandas as pd\n",
        "pd.set_option('display.max_rows', 50)\n",
        "import seaborn as sns\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import logging\n",
        "from scipy.stats import expon, poisson, uniform, lognorm\n",
        "\n",
        "from numpy.random import Generator, PCG64\n",
        "numpy_randomGen = Generator(PCG64(seed=1))\n",
        "\n",
        "\n",
        "import torch\n",
        "from torch.distributions import constraints\n",
        "from torch import tensor\n",
        "\n",
        "import pyro\n",
        "import pyro.distributions as dist\n",
        "from pyro.optim import ClippedAdam\n",
        "\n",
        "# Set matplotlib settings\n",
        "%matplotlib inline\n",
        "plt.style.use('default')\n",
        "plt.rcParams['figure.figsize'] = [8, 4]\n"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2021-09-15T11:59:37.295326Z",
          "iopub.execute_input": "2021-09-15T11:59:37.295724Z",
          "iopub.status.idle": "2021-09-15T11:59:53.721615Z",
          "shell.execute_reply.started": "2021-09-15T11:59:37.295626Z",
          "shell.execute_reply": "2021-09-15T11:59:53.720577Z"
        },
        "trusted": true,
        "id": "aKznBx1oisy5"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "logging.basicConfig(level=logging.DEBUG)"
      ],
      "metadata": {
        "id": "b1udn8WoU1pb"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Helper Functions"
      ],
      "metadata": {
        "id": "xOEFEnIuUsD1"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Truncated Exponential"
      ],
      "metadata": {
        "id": "4EDYPk5lU8qi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pyro.distributions as dist\n",
        "from torch.distributions.utils import broadcast_all\n",
        "\n",
        "def TruncatedExponential(low, high, rate=1.0):\n",
        "    '''\n",
        "    Usage: \n",
        "    d = TruncatedExponential(3, 10, 1.0).sample([1000])\n",
        "    sns.displot(data=d)\n",
        "    '''\n",
        "    low, high, rate = broadcast_all(low, high, rate)\n",
        "    return dist.TransformedDistribution(\n",
        "        dist.Uniform((-rate * high).exp(), (-rate * low).exp()),\n",
        "        [dist.transforms.ExpTransform().inv,\n",
        "         dist.transforms.AffineTransform(loc=0, scale=-1/rate)]\n",
        "    )\n"
      ],
      "metadata": {
        "id": "cz1Rlue-UtxR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "covs = torch.tensor([[2., -1.], [-1.,3.]])\n",
        "dist.MultivariateNormal(tensor([0.,0.]),covariance_matrix=covs).sample([5])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sXFlBUVeBWt3",
        "outputId": "05f3e633-0fe6-422a-fadb-171b1ee5a7eb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[-0.7182, -1.3469],\n",
              "        [ 1.5743, -2.6597],\n",
              "        [-1.9787,  1.5368],\n",
              "        [-0.7229, -2.2143],\n",
              "        [ 0.3651, -2.2745]])"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "sigma = dist.Exponential(1).expand([2]).sample()\n",
        "rho = dist.LKJ(2, 2).sample()\n",
        "cov = torch.outer(sigma, sigma)*rho"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uTEXKRuRDQeo",
        "outputId": "833f24c4-1940-4820-fee9-6c16bdb52a18"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[0.0013, 0.0066],\n",
              "        [0.0066, 0.6447]])"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "dist.Normal(0,3).expand([2]).to_event(1).sample()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qg_qVVRoVfCd",
        "outputId": "8c27d02d-f1e4-44c6-c84b-8afb7541cbbf"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([ 0.1741, -8.4035])"
            ]
          },
          "metadata": {},
          "execution_count": 52
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "mu_covariates = torch.ones([1,3])\n",
        "beta_mus = dist.Normal(0,5).expand([mu_covariates.size(1)]).to_event(1).sample().unsqueeze(-1)\n",
        "\n",
        "lambda_covariates = torch.ones([1,3])\n",
        "beta_lambdas = dist.Normal(0,3).expand([lambda_covariates.size(1)]).to_event(1).sample().unsqueeze(-1)"
      ],
      "metadata": {
        "id": "VSFwwv6aWOq0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "lambda_covariates, beta_lambdas, torch.mm(lambda_covariates, beta_lambdas)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kQQJRmerW9U9",
        "outputId": "0c4119b7-0db4-48d1-c5b7-007e07195256"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(tensor([[1., 1., 1.]]),\n",
              " tensor([ 1.1304, -2.6500, -2.1475]),\n",
              " tensor([-3.6671]))"
            ]
          },
          "metadata": {},
          "execution_count": 86
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "mu_covariates, beta_mus, torch.mm(mu_covariates ,beta_mus)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-SWDGsn4arNS",
        "outputId": "c548a612-2cc2-4785-c8f2-20a52a9190ce"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(tensor([[1., 1., 1.]]), tensor([[ 2.5492],\n",
              "         [-1.9735],\n",
              "         [ 3.8888]]), tensor([[4.4645]]))"
            ]
          },
          "metadata": {},
          "execution_count": 87
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "beta_mus.size()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ezshMfmXgMXZ",
        "outputId": "c5322222-c20b-4f56-8337-ae77901ef166"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([3])"
            ]
          },
          "metadata": {},
          "execution_count": 83
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "torch.ones([10,3])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Lf13r63tbNui",
        "outputId": "e688ebbb-149f-4ff9-c3ae-9c61b566eb7d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[1., 1., 1.],\n",
              "        [1., 1., 1.],\n",
              "        [1., 1., 1.],\n",
              "        [1., 1., 1.],\n",
              "        [1., 1., 1.],\n",
              "        [1., 1., 1.],\n",
              "        [1., 1., 1.],\n",
              "        [1., 1., 1.],\n",
              "        [1., 1., 1.],\n",
              "        [1., 1., 1.]])"
            ]
          },
          "metadata": {},
          "execution_count": 73
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "torch.ones([1,1]), torch.ones(1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CS4wOX8mhyQL",
        "outputId": "2903b15d-7648-41b0-9dae-e77cf178dac9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(tensor([[1.]]), tensor([1.]))"
            ]
          },
          "metadata": {},
          "execution_count": 89
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#parameters from RFM (x, tx, Tcal)\n",
        "#for each customer we will have: repeat_purchases x, date of last purchase tx, period of observation Tcal from first purchase to time of measurement ]  \n",
        "\n",
        "def btyd_abe_model(*, x, tx, Tcal, lambda_covariates = None, mu_covariates = None, prior_only=True):\n",
        "  '''\n",
        "  x: number of REPEAT purchases after the first. Must be > 0.\n",
        "  tx: date of last purchase\n",
        "  Tcal: observation date\n",
        "  lambda_covariates: \n",
        "  mu_covariates:\n",
        "  prior_only:\n",
        "\n",
        "  returns: Not a pure function, needed for sampling and pyro param store\n",
        "  '''\n",
        "  N = x.size(0) #num of customers\n",
        "\n",
        "  if lambda_covariates is None:\n",
        "    lambda_covariates = torch.ones([N,1]) #intercept only\n",
        "  else:#TODO might need to unsqueeze the lambda_covariates if it is not 2D\n",
        "    lambda_covariates = torch.hstack((torch.ones([N,1], lambda_covariates)))\n",
        "\n",
        "  if mu_covariates is None:\n",
        "    mu_covariates = torch.ones([N,1]) #intercept only\n",
        "  else: #TODO might need to unsqueeze the lambda_covariates if it is not 2D\n",
        "    mu_covariates = torch.hstack((torch.ones([N,1], lambda_covariates)))\n",
        "\n",
        "  z = None #TODO FIX\n",
        "  y = None #TODO FIX\n",
        "\n",
        "  #TODO Convert original pareto/NBD loglik function :==> non-centered Pareto/NBD Abe 2009 formulation\n",
        "  def loglik(*, lambda_, mu, x, tx, Tcal, y, z):\n",
        "    target = x * torch.log(lambda_) - torch.log(lambda_ + mu)\n",
        "    n = lambda_.size(0)\n",
        "    for i in range(n):\n",
        "      target  = target + torch.logaddexp(torch.log(lambda_[i]) - (lambda_[i] + mu[i]) * Tcal[i],\n",
        "                                        torch.log(mu[i]) - (lambda_[i] + mu[i]) * tx[i]\n",
        "                                        )\n",
        "    return target\n",
        "  \n",
        "  sigmas = pyro.sample('sigmas', dist.Exponential(1).expand([2]))\n",
        "  rho = pyro.sample('rho', dist.LKJ(2, 2))\n",
        "  cov = torch.outer(sigmas, sigmas)*rho\n",
        "\n",
        "  # mu_mean # TODO can initialize w/informed prior using average computed from data\n",
        "  # lambda_mean # TODO can initialize w/informed prior using average computed from data\n",
        "\n",
        "\n",
        "  beta_mus = pyro.sample('beta_mus', dist.Normal(0,3).expand([N, mu_covariates.size(1)]))\n",
        "  beta_lambdas = pyro.sample('beta_lambdas', dist.Normal(0,3).expand([N, lambda_covariates.size(1)]))\n",
        "  mu_mean, lambda_mean = 0., 0. #TODO fix #mu_mean, lambda_mean = torch.mm(torch.t(mu_covariates), beta_mus), torch.mm(torch.t(lambda_covariates), beta_lambdas)\n",
        "  with pyro.plate('data', N):\n",
        "    mu_lambda = pyro.sample('mu_lambda', dist.MultivariateNormal(tensor([mu_mean, lambda_mean]), cov)).exp()\n",
        "\n",
        "  mu, lambda_ = mu_lambda[:,0], mu_lambda[:,1]\n",
        "  mu_plus_lambda = mu + lambda_\n",
        "\n",
        "  if not prior_only:\n",
        "    # sample z\n",
        "    # sample dropout time y from double truncated exponential if z == 0\n",
        "    # compute loglik using mu, lambda_, z, and y . Note z and y are same shape as x, tx, and Tcal\n",
        "    pyro.factor('loglik', loglik(lambda_, mu,x, tx, Tcal)\n"
      ],
      "metadata": {
        "id": "3hKCYkocTPTs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x, tx, Tcal = tensor([2.,3., 4., 5.]), tensor([2.,3., 4., 5.]), tensor([2.,3., 4., 5.])\n",
        "dat = {'x':x, 'tx':tx, 'Tcal':Tcal}\n",
        "\n",
        "from pyro.infer import MCMC, NUTS\n",
        "model = btyd_abe_model\n",
        "mcmc = MCMC(NUTS(model), num_samples=100, warmup_steps=200)\n",
        "\n",
        "mcmc.run(**dat, prior_only=True)"
      ],
      "metadata": {
        "id": "X8F2v7_JV1V4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "416096bb-7d65-40f0-e8b3-1483bd70a8b9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Warmup:   0%|          | 0/300 [02:55, ?it/s]\n",
            "Warmup:   0%|          | 0/300 [02:13, ?it/s]\n",
            "Sample: 100%|██████████| 300/300 [02:10,  2.29it/s, step size=9.76e-02, acc. prob=0.927]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "samples = mcmc.get_samples()\n",
        "hmc_samples = {k: v.detach().cpu().numpy() for k, v in samples.items()}\n",
        "hmc_samples.keys()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "53QNRl8FJU9H",
        "outputId": "91057551-b207-494b-dab0-1039458f1209"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "dict_keys(['beta_lambdas', 'beta_mus', 'mu_lambda', 'rho', 'sigmas'])"
            ]
          },
          "metadata": {},
          "execution_count": 111
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "hmc_samples['sigmas'].shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7bLrY2ESLgve",
        "outputId": "144fe9a7-dab4-410f-df00-6700a578cfde"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(100, 2)"
            ]
          },
          "metadata": {},
          "execution_count": 112
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "sns.scatterplot(x=hmc_samples['sigmas'][:, 0], y=hmc_samples['sigmas'][:,1]);"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 368
        },
        "id": "eNbDKhwRMRPF",
        "outputId": "6505d955-1b4d-4592-c058-637f8b757a6d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 800x400 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Text1"
      ],
      "metadata": {
        "id": "od0WqsMcV15Y"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Text2"
      ],
      "metadata": {
        "id": "ImIg-6JdV2yZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "eamOx2BUV0Yq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Text3"
      ],
      "metadata": {
        "id": "kLUB8UFUV0Iv"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Description of the simulation model"
      ],
      "metadata": {
        "id": "a6JaJcggVwVH"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let’s describe the model first by simulation. \n",
        "\n",
        "Suppose we have a company that is 2 years old and a total of 2000 customers, C, that have made at least one purchase from us. \n",
        "\n",
        "We’ll assume a linear rate of customer acquisition, so that the first purchase date is simply a uniform random variable over the 2 years of the company existance. These assumptions are just to keep the example concrete, and are not so important for understanding the model."
      ],
      "metadata": {
        "id": "M8XPw-evgBdu"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Each customer c∈C is assumed to have a certain lifetime, τc, starting on their join-date. \n",
        "\n",
        "During their lifetime, they will purchase at a constant rate, λc, so that they will make k∼Poisson(tλc) purchases over a time-interval t. \n",
        "\n",
        "Once their lifetime is over, they will stop purchasing. We only observe the customer for Tc units of time, and this observation time can be either larger or smaller than the lifetime, τc. \n",
        "\n",
        "Since we don’t observe τc itself, we will assume it follows an exponential distribution, i.e. τc∼Exp(μc)."
      ],
      "metadata": {
        "id": "MjtZTqtPgajd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "BvV5LWUU8kNr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def create_start_dates(n, max_number_of_periods):\n",
        "  '''\n",
        "  returns an array of n start dates in interval [0, max_number_of_periods)\n",
        "  \n",
        "  inputs \n",
        "  int n: number of customers to generate\n",
        "  int max_number_of_periods: max number of periods customer can be observed in simulation\n",
        "\n",
        "  output: \n",
        "  start_date[n]: starting period of customer n, starting from 0\n",
        "  '''\n",
        "  return np.random.default_rng(1).integers(low=0, high=max_number_of_periods, size=n)"
      ],
      "metadata": {
        "id": "C5YZkVe7-WwF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def simulate_purchases(*,T, mean_customer_lifetime, \n",
        "                       mean_period_between_purchases,\n",
        "                       max_number_of_periods,\n",
        "                       var_customer_lifetime = None, \n",
        "                       var_period_between_purchases = None \n",
        "                        ):\n",
        "  '''\n",
        "  input: \n",
        "  T: customer enrollment date\n",
        "\n",
        "  mean_customer_lifetime: mean of customer lifetime, in periods\n",
        "  var_customer_lifetime: var of customer lifetime\n",
        "  mean_period_between_purchases: mean period between purchases\n",
        "  var_period_between_purchases: var of period between purchases\n",
        "\n",
        "  output:\n",
        "  k: number of purchases\n",
        "  T: customer enrollment date\n",
        "  obs_time = This is the length of time they have been a customer, max_number_of_periods - T\n",
        "  tau: actual (latent) lifetime for this customer (drawn from exponential distribution with scale=mean_customer_lifetime)\n",
        "  mean_customer_lifetime: mean_customer_lifetime\n",
        "  1./mean_customer_lifetime :  reciprocal of mean customer lifetime\n",
        "  '''\n",
        "  from scipy.stats import expon\n",
        "  \n",
        "  obs_time = max_number_of_periods - T\n",
        "  assert obs_time > 0, \"time as enrolled customer cannot be negative\"\n",
        "  assert mean_customer_lifetime > 0 , \"mean customer lifetime must be > 0\"\n",
        "  assert mean_period_between_purchases > 0, \"mean period between purchases must be > 0\"\n",
        "  \n",
        "  tau = expon.rvs(scale=mean_customer_lifetime) # actual lifetime for this customer\n",
        "  t, k = T, 0 \n",
        "  wait = expon.rvs(scale=mean_period_between_purchases) # waiting time between purchases\n",
        "  while ((t + wait) < min(max_number_of_periods, T + tau)): \n",
        "    t = t + wait\n",
        "    k = k + 1\n",
        "    wait = expon.rvs(scale=mean_period_between_purchases)\n",
        "\n",
        "  return  T,  obs_time, k, tau, t, mean_customer_lifetime, 1./mean_customer_lifetime  #final value of t is time of last purchased\n",
        "\n",
        "simulate_purchases_vec = np.vectorize(simulate_purchases)\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "wYOxTjogN8C0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "simulate_purchases(T=20.,\n",
        "                   max_number_of_periods=100.,\n",
        "                   mean_customer_lifetime=30.,\n",
        "                   mean_period_between_purchases=8.\n",
        "                   )"
      ],
      "metadata": {
        "id": "D-w1zEvjgV7j"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "9ysonmT1iA_k"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def create_customer_df(*,\n",
        "                       n, \n",
        "                       mean_customer_lifetime, \n",
        "                       mean_period_between_purchases, \n",
        "                       max_number_of_periods, \n",
        "                       var_customer_lifetime = None, \n",
        "                       var_period_between_purchases = None\n",
        "                       ):\n",
        "  '''\n",
        "  output: \n",
        "    dataframe[['enrollment_date', \n",
        "    'T_observed',\n",
        "    'purchases', \n",
        "    'tau', : lifetime for this simulated customer drawn from exponential distribution with scale=mean_customer_lifetime\n",
        "    'date_of_last_purchase', \n",
        "    'mean_customer_lifetime',\n",
        "    '1/mean_customer_lifetime'\n",
        "\n",
        "  '''\n",
        "  T =  create_start_dates(n=n, max_number_of_periods=max_number_of_periods)\n",
        "  result = np.round(\n",
        "      simulate_purchases_vec(T=T, \n",
        "                             mean_customer_lifetime=mean_customer_lifetime, \n",
        "                             mean_period_between_purchases=mean_period_between_purchases,\n",
        "                             max_number_of_periods=max_number_of_periods\n",
        "\n",
        "                             )\n",
        "          ,2)\n",
        "  return pd.DataFrame(result, index=['enrollment_date', \n",
        "                                     'T_observed',\n",
        "                                     'purchases', \n",
        "                                     'tau', \n",
        "                                     'date_of_last_purchase', \n",
        "                                     'mean_customer_lifetime',\n",
        "                                     '1/mean_customer_lifetime']).T\n"
      ],
      "metadata": {
        "id": "QkKlXzQDaJu0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "max_number_of_periods=60\n",
        "customers = create_customer_df(n=20, \n",
        "                               mean_customer_lifetime=30, \n",
        "                               mean_period_between_purchases=8, \n",
        "                               max_number_of_periods=max_number_of_periods)\n",
        "customers"
      ],
      "metadata": {
        "id": "ekLLY1qnfxB2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "customers.describe().T"
      ],
      "metadata": {
        "id": "SZEHV2sLmRhA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data = customers[customers['purchases'] >= 2.].copy()\n",
        "data.describe().T"
      ],
      "metadata": {
        "id": "ECYID91fqVOp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "t, T, k = tensor(data['date_of_last_purchase'].values), tensor(data['T_observed'].values), tensor(data['purchases'].values)"
      ],
      "metadata": {
        "id": "2rTilK_-miyI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data=dist.Gamma(concentration=2, rate=1).expand([1000]).sample()\n",
        "print(data.min(),  data.median(), data.mean(),data.max(), data.var())\n",
        "sns.displot(data=data);"
      ],
      "metadata": {
        "id": "xzUMFa0KlXXN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "h2VDWTeNOYr1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Inverse Gamma: for concentration > 2, \n",
        "#     mean = rate/(concentration - 1)\n",
        "#      var ~ concentration^2 / rate ^3\n",
        "#     MEDIAN  ~ rate / concentration\n",
        "\n",
        "# Gamma:\n",
        "# mean = concentration / rate\n",
        "# var = concentration / rate ^2\n",
        "\n",
        "data=dist.InverseGamma(concentration=7,rate=70.).expand([10000]).sample()\n",
        "\n",
        "print(data.min(),  data.median(), data.mean(), data.max(), data.var())\n",
        "sns.displot(data=data);"
      ],
      "metadata": {
        "id": "hnPI9A1aFuSP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data=dist.HalfNormal(scale=200).expand([10000]).sample()\n",
        "\n",
        "print(data.min(),  data.median(), data.mean(), data.max(), data.var())\n",
        "sns.displot(data=data);"
      ],
      "metadata": {
        "id": "SUjDQGEGLI9k"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Model Definition"
      ],
      "metadata": {
        "id": "GetrCeCLlpN6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# def model_half_normal_priors(t, T, k, prior_only=False):\n",
        "#   '''\n",
        "#   input:\n",
        "#   vector t (nx1)  = time since most recent purchase (recency)\n",
        "#   vector T (nx1) = total observation time\n",
        "#   vector k (nx1) = number of purchases observed (k must be >= 2)\n",
        "\n",
        "#   n, etau_alpha, etau_beta, Lambda_alpha, Lambda_beta are scalars\n",
        "#   n = number of customers\n",
        "#   etau_alpha, etau_beta are priors for etau\n",
        "#   Lambda_alpha, Lambda_beta are priors for Lambda\n",
        "#   '''\n",
        "#   assert torch.all(k >=2.), \"There are illegal values of k. k must be >= 2\"\n",
        "\n",
        "#   def loglik(Lambda, mu, t, T, k):\n",
        "#     target = k * torch.log(Lambda) - torch.log(Lambda + mu)\n",
        "#     n = Lambda.size(0)\n",
        "#     for i in range(n):\n",
        "#       target  = target + torch.logaddexp(torch.log(Lambda[i]) - (Lambda[i] + mu[i]) * T[i],\n",
        "#                                         torch.log(mu[i]) - (Lambda[i] + mu[i]) * t[i]\n",
        "#                                         )\n",
        "#     return target\n",
        "  \n",
        "#   etau_alpha = pyro.sample('tau_alpha', dist.HalfNormal(scale=1))\n",
        "#   etau_beta = pyro.sample('tau_beta', dist.HalfNormal(scale=200))\n",
        "#   Lambda_alpha = pyro.sample('Lambda_alpha', dist.HalfNormal(scale=1))\n",
        "#   Lambda_beta = pyro.sample('Lambda_beta', dist.HalfNormal(scale=200))\n",
        "\n",
        "#   if not prior_only:\n",
        "#     with pyro.plate(\"data\", t.size(0)):\n",
        "#       etau  = pyro.sample('etau', dist.InverseGamma(etau_alpha, etau_beta)) #mean lifetime\n",
        "#       mu = pyro.deterministic('mu', 1./tau)\n",
        "#       Lambda = pyro.sample('Lambda', dist.Gamma(Lambda_alpha, Lambda_beta))\n",
        "#       one_over_Lambda = pyro.deterministic('one_over_Lambda', 1./Lambda)\n",
        "#     pyro.factor('loglik', loglik(Lambda, mu, t, T, k))"
      ],
      "metadata": {
        "id": "5XMcuD0pLynK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "5j9uqfkpPhM5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "bfB7Jr3nPg_m"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# def model_test(t, T, k, prior_only=False):\n",
        "#   '''\n",
        "#   input:\n",
        "#   vector t (nx1)  = time since most recent purchase (recency)\n",
        "#   vector T (nx1) = total observation time\n",
        "#   vector k (nx1) = number of purchases observed (k must be >= 2)\n",
        "\n",
        "#   n, etau_alpha, etau_beta, Lambda_alpha, Lambda_beta are scalars\n",
        "#   n = number of customers\n",
        "#   etau_alpha, etau_beta are priors for etau\n",
        "#   Lambda_alpha, Lambda_beta are priors for Lambda\n",
        "#   '''\n",
        "#   assert torch.all(k >=2.), \"There are illegal values of k. k must be >= 2\"\n",
        "\n",
        "#   def loglik(Lambda, mu, t, T, k):\n",
        "#     target = k * torch.log(Lambda) - torch.log(Lambda + mu)\n",
        "#     n = Lambda.size(0)\n",
        "#     for i in range(n):\n",
        "#       target  = target + torch.logaddexp(torch.log(Lambda[i]) - (Lambda[i] + mu[i]) * T[i],\n",
        "#                                         torch.log(mu[i]) - (Lambda[i] + mu[i]) * t[i]\n",
        "#                                         )\n",
        "#     return target\n",
        "  \n",
        "#   etau_alpha = pyro.sample('tau_alpha', dist.HalfCauchy(scale=2))\n",
        "#   etau_beta = pyro.sample('tau_beta', dist.HalfCauchy(scale=2), constraint=constraints.positive)\n",
        "#   Lambda_alpha = pyro.sample('Lambda_alpha', dist.HalfCauchy(scale=2), constraint=constraints.positive)\n",
        "#   Lambda_beta = pyro.sample('Lambda_beta', dist.HalfCauchy(scale=2), constraint=constraints.positive)\n",
        "\n",
        "#   if not prior_only:\n",
        "#     with pyro.plate(\"data\", t.size(0)):\n",
        "#       etau  = pyro.sample('etau', dist.InverseGamma(etau_alpha, etau_beta)) #mean lifetime\n",
        "#       mu = pyro.deterministic('mu', 1./tau)\n",
        "#       Lambda = pyro.sample('Lambda', dist.Gamma(Lambda_alpha, Lambda_beta))\n",
        "#       one_over_Lambda = pyro.deterministic('one_over_Lambda', 1./Lambda)\n",
        "#     pyro.factor('loglik', loglik(Lambda, mu, t, T, k))"
      ],
      "metadata": {
        "id": "I8ImhM3cicce"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from pyro.infer import MCMC, NUTS\n",
        "model = model_half_normal_priors\n",
        "nuts_kernel = NUTS(model)\n",
        "mcmc = MCMC(nuts_kernel, num_samples=1000, warmup_steps=250)\n",
        "\n",
        "mcmc.run(t, T, k, prior_only=True)"
      ],
      "metadata": {
        "id": "XQm0KyHKiJAz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "samples = mcmc.get_samples()\n",
        "hmc_samples = {k: v.detach().cpu().numpy() for k, v in samples.items()}\n",
        "hmc_samples.keys()"
      ],
      "metadata": {
        "id": "1WcRheyciI4D"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = model_test\n",
        "nuts_kernel = NUTS(model, jit_compile=False)\n",
        "mcmc = MCMC(nuts_kernel, num_samples=1000, warmup_steps=250)\n",
        "\n",
        "mcmc.run(t, T, k, prior_only=False)"
      ],
      "metadata": {
        "id": "6JJWTUk-k0aq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "samples = mcmc.get_samples()\n",
        "hmc_samples = {k: v.detach().cpu().numpy() for k, v in samples.items()}\n",
        "keys = hmc_samples.keys()"
      ],
      "metadata": {
        "id": "Fyod-BaOo_yA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for key in keys:\n",
        "  print(key, hmc_samples[key].shape)"
      ],
      "metadata": {
        "id": "IRDKxerQpcX7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "store = pyro.get_param_store()\n",
        "for key in store.keys():\n",
        "  print(key, store[key])"
      ],
      "metadata": {
        "id": "08BSgwhXsrIp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "Wqw3kfN_vHp9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "Suj2SGxMvHjU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "_665Z_rcvHZO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## sidebar"
      ],
      "metadata": {
        "id": "JcOz43EYu7vH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "Lambda = pd.DataFrame(hmc_samples['Lambda'])\n",
        "mu = pd.DataFrame(1. /hmc_samples['Lambda'])\n",
        "tau = pd.DataFrame(hmc_samples['tau'])"
      ],
      "metadata": {
        "id": "s8IMOlzvqujh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pd.set_option('display.max_rows', 20)"
      ],
      "metadata": {
        "id": "JucK90v8r2il"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "Lambda.describe().T"
      ],
      "metadata": {
        "id": "KpNP99nIrOV1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "mu.describe().T"
      ],
      "metadata": {
        "id": "aoTxN1qFseDE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tau.describe().T"
      ],
      "metadata": {
        "id": "wXlBQhhmrWsW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data"
      ],
      "metadata": {
        "id": "RFUvG1vTpENC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data.shape"
      ],
      "metadata": {
        "id": "22HRZIYet0-q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data.head()"
      ],
      "metadata": {
        "id": "qkG_jJPot5yM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pd.concat([data.reset_index(),mu.describe().T ], axis=1) # is this valid? IDK"
      ],
      "metadata": {
        "id": "71P4dCg4tUW8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pd.concat([data.reset_index(),tau.describe().T ], axis=1)"
      ],
      "metadata": {
        "id": "Qlb88hDjthmY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# model = model_test\n",
        "# nuts_kernel_jit = NUTS(model, jit_compile=True, ignore_jit_warnings=True)\n",
        "# mcmc_jit = MCMC(nuts_kernel_jit, num_samples=1000, warmup_steps=250)\n",
        "\n",
        "# mcmc_jit.run(t, T, k, prior_only=False)"
      ],
      "metadata": {
        "id": "GeAROPQYk0Nu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "RoO9RIb5k0E2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "Ccpp47XJkz8k"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "2-SYeEgZkzyx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## original model"
      ],
      "metadata": {
        "id": "oIsYOACkk45H"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def model_one(t, T, k, prior_only=False):\n",
        "  '''\n",
        "  input:\n",
        "  vector t (nx1)  = time since most recent purchase (recency)\n",
        "  vector T (nx1) = total observation time\n",
        "  vector k (nx1) = number of purchases observed (k must be >= 2)\n",
        "\n",
        "  n, etau_alpha, etau_beta, Lambda_alpha, Lambda_beta are scalars\n",
        "  n = number of customers\n",
        "  etau_alpha, etau_beta are priors for etau\n",
        "  Lambda_alpha, Lambda_beta are priors for Lambda\n",
        "  '''\n",
        "  assert torch.all(k >=2.), \"There are illegal values of k. k must be >= 2\"\n",
        "\n",
        "  def loglik(Lambda, mu, t, T, k):\n",
        "    target = k * torch.log(Lambda) - torch.log(Lambda + mu)\n",
        "    n = Lambda.size(0)\n",
        "    for i in range(n):\n",
        "      target  = target + torch.logaddexp(torch.log(Lambda[i]) - (Lambda[i] + mu[i]) * T[i],\n",
        "                                        torch.log(mu[i]) - (Lambda[i] + mu[i]) * t[i]\n",
        "                                        )\n",
        "    return target\n",
        "  \n",
        "  # etau_alpha = pyro.sample('etau_alpha', dist.)\n",
        "  # etau_beta = pyro.sample('etau_beta', dist)\n",
        "  # Lambda_alpha = pyro.sample('Lambda_alpha', dist)\n",
        "  # Lambda_beta = pyro.sample('Lambda_beta', dist)\n",
        "\n",
        "  with pyro.plate(\"data\", t.size(0)):\n",
        "    etau  = pyro.sample('etau', dist.InverseGamma(etau_alpha, etau_beta))\n",
        "    mu = 1./etau\n",
        "    Lambda = pyro.sample('Lambda', dist.Gamma(Lambda_alpha, Lambda_beta))\n",
        "\n",
        "  if prior_only:\n",
        "    pyro.factor('loglik', loglik(Lambda, mu, t, T, k))\n",
        "  else:\n",
        "    pyro.factor('zero', 0)"
      ],
      "metadata": {
        "id": "UbZZAZQJfbb-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "zJX96GcqiaRp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## create data"
      ],
      "metadata": {
        "id": "IdaeP-s_k_zr"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Perform MCMC"
      ],
      "metadata": {
        "id": "VA5Aa_Q1fkE6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from pyro.infer import MCMC, NUTS\n",
        "model = model_test\n",
        "nuts_kernel = NUTS(model)\n",
        "mcmc = MCMC(nuts_kernel, num_samples=1000, warmup_steps=250)\n",
        "\n",
        "mcmc.run(t, T, k, prior_only=True)"
      ],
      "metadata": {
        "id": "qN0a8ZjMa4H4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "samples = mcmc.get_samples()\n",
        "hmc_samples = {k: v.detach().cpu().numpy() for k, v in samples.items()}\n",
        "hmc_samples.keys()"
      ],
      "metadata": {
        "id": "k5sSaGJthRW1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for key in hmc_samples.keys():\n",
        "  sns.kdeplot(data = hmc_samples[key])"
      ],
      "metadata": {
        "id": "7CBnPcwahRS7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Centered BTYD"
      ],
      "metadata": {
        "id": "XZxpKYo-fWZU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# https://www.briancallander.com/posts/customer_lifetime_value/models/rf.stan\n",
        "# data_hyperpriors <- list(\n",
        "#   log_life_mean_mu = log(31),\n",
        "#   log_life_mean_sigma = 0.7,\n",
        "#   log_life_scale_sigma = 0.8,\n",
        "\n",
        "#   log_lambda_mean_mu = log(1 / 14),\n",
        "#   log_lambda_mean_sigma = 0.3,\n",
        "#   log_lambda_scale_sigma = 0.5\n",
        "# )\n",
        "data {\n",
        "  int<lower = 1> n;       // number of customers\n",
        "  vector<lower = 0>[n] t; // time to most recent purchase\n",
        "  vector<lower = 0>[n] T; // total observation time\n",
        "  vector<lower = 0>[n] k; // number of purchases observed\n",
        "\n",
        "  // user-specified parameters\n",
        "  real<lower = 0> etau_mean_alpha;\n",
        "  real<lower = 0> etau_mean_beta;\n",
        "  real<lower = 0> etau_sd_alpha;\n",
        "  real<lower = 0> etau_sd_beta;\n",
        "\n",
        "  real<lower = 0> lambda_mean_alpha;\n",
        "  real<lower = 0> lambda_mean_beta;\n",
        "  real<lower = 0> lambda_sd_alpha;\n",
        "  real<lower = 0> lambda_sd_beta;\n",
        "}\n",
        "\n",
        "parameters {\n",
        "  vector<lower = 0>[n] lambda; // purchase rate\n",
        "  vector<lower = 0>[n] etau;   // expected mean lifetime\n",
        "\n",
        "  vector<lower = 0>[n] etau_mean; // mean expected life span\n",
        "  vector<lower = 0>[n] etau_sd;\n",
        "  vector<lower = 0>[n] lambda_mean; // mean purchase rate\n",
        "  vector<lower = 0>[n] lambda_sd;\n",
        "\n",
        "}\n",
        "\n",
        "transformed parameters {\n",
        "  vector<lower = 0>[n] etau_beta = etau_mean;\n",
        "  vector<lower = 0>[n] etau_alpha = etau_sd;\n",
        "  vector<lower = 0>[n] lambda_beta = lambda_mean ./ (lambda_sd .* lambda_sd);\n",
        "  vector<lower = 0>[n] lambda_alpha = lambda_beta .* lambda_mean;\n",
        "\n",
        "  vector<lower = 0>[n] mu = 1.0 ./ etau;\n",
        "}\n",
        "\n",
        "model {\n",
        "  // hyperpriors\n",
        "  etau_mean ~ gamma(etau_mean_alpha, etau_mean_beta);\n",
        "  etau_sd ~ gamma(etau_sd_alpha, etau_sd_beta);\n",
        "\n",
        "  lambda_mean ~ gamma(lambda_mean_alpha, lambda_mean_beta);\n",
        "  lambda_sd ~ gamma(lambda_sd_alpha, lambda_sd_beta);\n",
        "\n",
        "  // priors\n",
        "  etau ~ inv_gamma(etau_alpha, etau_beta);\n",
        "  lambda ~ gamma(lambda_alpha, lambda_beta);\n",
        "\n",
        "  // likelihood\n",
        "  target += k .* log(lambda) - log(lambda + mu);\n",
        "  for (i in 1:n) {\n",
        "    target += log_sum_exp(\n",
        "      log(lambda[i]) - (lambda[i] + mu[i]) .* T[i],\n",
        "      log(mu[i]) - (lambda[i] + mu[i]) .* t[i]\n",
        "    );\n",
        "  }\n",
        "}\n"
      ],
      "metadata": {
        "id": "Sme-1n-EhRG8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Non-centered BTYD"
      ],
      "metadata": {
        "id": "nUSy4aCHfbpl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# non-centered BTYD\n",
        "# https://www.briancallander.com/posts/customer_lifetime_value/recency_frequency.html\n",
        "# https://www.briancallander.com/posts/customer_lifetime_value/models/rf_noncentred.stan\n",
        "\n",
        "data {\n",
        "  int<lower = 1> n;       // number of customers\n",
        "  vector<lower = 0>[n] t; // time between first and last purchase\n",
        "  vector<lower = 0>[n] T; // total observation time\n",
        "  vector<lower = 0>[n] k; // number of purchases\n",
        "\n",
        "  // hyperparameters for the expected lifetime\n",
        "  real log_life_mean_mu;\n",
        "  real<lower = 0> log_life_mean_sigma;\n",
        "  // hyperparameter for scale of customer-level lifetime effects\n",
        "  real<lower = 0> log_life_scale_sigma;\n",
        "\n",
        "  // hyperparameters for the expected purchase rate\n",
        "  real log_lambda_mean_mu;\n",
        "  real<lower = 0> log_lambda_mean_sigma;\n",
        "  // hyperparameter for scale of customer-level purchase-rate effects\n",
        "  real<lower = 0> log_lambda_scale_sigma;\n",
        "\n",
        "  // flag whether to only sample from the prior\n",
        "  // to draw from the prior-predictive distribution: prior_only = 1\n",
        "  // to draw from the posterior distribution: prior_only = 0\n",
        "  int<lower = 0, upper = 1> prior_only;\n",
        "}\n",
        "\n",
        "transformed data {\n",
        "  vector<lower = 0, upper = 0>[2] zero = rep_vector(0, 2);\n",
        "  vector[2] J = [-1, 1]';\n",
        "  vector[2] m = [log_life_mean_mu, log_lambda_mean_mu]';\n",
        "  matrix<lower = 0>[2, 2] m_sigma = diag_matrix([log_life_mean_sigma, log_lambda_mean_sigma]');\n",
        "  matrix<lower = 0>[2, 2] s_sigma = diag_matrix([log_life_scale_sigma, log_lambda_scale_sigma]');\n",
        "}\n",
        "\n",
        "parameters {\n",
        "  row_vector[2] log_centres;\n",
        "  vector<lower = 0>[2] scales;\n",
        "  matrix[n, 2] customer; // customer-level effects\n",
        "}\n",
        "\n",
        "transformed parameters {\n",
        "  matrix<lower = 0>[n, 2] theta = exp(\n",
        "    diag_post_multiply(\n",
        "      rep_matrix(log_centres, n) + diag_post_multiply(customer, scales),\n",
        "      J\n",
        "    )\n",
        "  ); // (mu, lambda)\n",
        "}\n",
        "\n",
        "model {\n",
        "  // priors\n",
        "  log_centres ~ multi_normal_cholesky(m, m_sigma);\n",
        "  scales ~ multi_normal_cholesky(zero, s_sigma);\n",
        "\n",
        "  for (i in 1:n) {\n",
        "\n",
        "    customer[i, ] ~ std_normal();\n",
        "\n",
        "    // likelihood\n",
        "    if (prior_only == 0) {\n",
        "      target += log_sum_exp(\n",
        "        log(theta[i, 2]) - (theta[i, 2] + theta[i, 1]) .* T[i],\n",
        "        log(theta[i, 1]) - (theta[i, 2] + theta[i, 1]) .* t[i]\n",
        "      );\n",
        "    }\n",
        "  }\n",
        "\n",
        "  if (prior_only == 0) {\n",
        "    target += k .* log(theta[, 2]) - log(theta[, 2] + theta[, 1]);\n",
        "  }\n",
        "\n",
        "}\n"
      ],
      "metadata": {
        "id": "Ro27nMERhRC0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "Z0rsJXyYhQ-l"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "FH8phAQghQ6M"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "zEmNp40EhQ08"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "flVVOL4xhQv1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "wdwtKGxghQoZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "z-qcdufPhQd4"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}