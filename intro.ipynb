{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Source: https://github.com/mwestt/An-Introduction-to-Bayesian-Inference-in-PyStan\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction\n",
    "\n",
    "\"The many virtues of Bayesian approaches in data science are seldom understated. Unlike the comparatively dusty frequentist tradition that defined statistics in the 20th century, Bayesian approaches match more closely the inference that human brains perform, by combining data-driven likelihoods with prior beliefs about the world. This kind of approach has been fruitfully applied in [reinforcement learning](https://people.eecs.berkeley.edu/~avivt/BRLS_journal.pdf), and efforts to incorporate it into deep learning are a hot area of [current research](https://alexgkendall.com/computer_vision/bayesian_deep_learning_for_safe_ai/). Indeed, it has been [argued](https://link.springer.com/chapter/10.1007/978-94-010-1436-6_6) that Bayesian statistics is the more fundamental of the two statistical schools of thought, and should be the preferred picture of statistics when first introducing students to the subject.\n",
    "\n",
    "As the predictions from Bayesian inference are probability distributions rather than point estimates, this allows for the quantification of uncertainty in the inferences that are made, which is often missing from the predictions made by machine learning methods.\n",
    "\n",
    "Although there are clear motivations for incorporating Bayesian approaches into machine learning, there are computational challenges present in actually implementing them. Often, it is not practical to analytically compute the required distributions, and stochastic sampling methods such as [Markov chain Monte Carlo](https://jeremykun.com/2015/04/06/markov-chain-monte-carlo-without-all-the-bullshit/) (MCMC) are used instead. One way of implementing MCMC methods in a transparent and efficient way is via the probabilistic programming language, [Pyro](https://pyro.ai/). \n",
    "\n",
    "## Bayes' Theorem\n",
    "\n",
    "The crux of Bayesian inference is in [Bayes' theorem](https://en.wikipedia.org/wiki/Bayes%27_theorem), which was discovered by the Reverend Thomas Bayes in the 18th century. It's based on a fundamental result from probability theory, which you may have seen before:\n",
    "\n",
    "$$P(A|B) = \\frac{P(B|A)P(A)}{ P(B)}$$\n",
    "\n",
    "That thing on the left is our posterior, which is the distribution we're interested in. On the right-hand side, we have the likelihood, which is dependent on our model and data, multiplied by the prior, which represents our pre-existing beliefs, and divided by the marginal likelihood which normalises the distribution. \n",
    "\n",
    "This theorem can be used to arrive at many counterintuitive results, that are nonetheless true. Take, for instance, the example of [false positives](https://en.wikipedia.org/wiki/Bayes'_theorem#Drug_testing) in drug tests being much higher when the test population is heavily skewed. Rather than go into detail on the basics of Bayesian statistics, I'm going to press onward to discussing inference with Stan. William Koehrsen has some great material for understanding the intuition behind Bayes' theorem [here](https://towardsdatascience.com/bayes-rule-applied-75965e4482ff).\n",
    "\n",
    "# Motivating the use of a Bayesian Model Framework like Pyro\n",
    "\n",
    "Bayesian inference is *hard*. The reason for this, according to statistician Don Berry:\n",
    "\n",
    "> *\"Bayesian inference is hard in the sense that thinking is hard.\" -- Don Berry*\n",
    "\n",
    "Well, OK. What I suppose he means here is that there's little mathematical overhead that gets in the way of making inferences using Bayesian methods, and so the difficulties come from the problems being conceptually difficult rather than any technical or methodological abstraction. But more concretely, Bayesian inference is hard because *solving integrals is hard*. That $P(B)$ up there involves an integral over all possible values that the model parameters can take. Luckily, we're not totally at a loss, as it is possible to construct an approximation to the posterior distribution by drawing samples from it, and creating a histogram of those sampled values to serve as the desired posterior. \n",
    "\n",
    "## MCMC Methods\n",
    "\n",
    "In generating those samples, we need a methodological framework to govern how the sampler should move through the parameter space. A popular choice is Markov chain Monte Carlo. MCMC is a class of methods that combines two powerful concepts: Markov chains and Monte Carlo sampling. [Markov chains](http://setosa.io/ev/markov-chains/) are stochastic processes that evolve over time in a \"memoryless\" way, known as the *Markov property*. The Markov property means that the state of a Markov chain transitions to another state with a probability that depends only on the *most recent* state of the system, and not its entire history. Monte Carlo sampling, on other hand, involves solving deterministic problems by repeated random sampling. The canonical way of doing this is with the [Metropolis-Hastings](https://twiecki.github.io/blog/2015/11/10/mcmc-sampling/) algorithm. Stan instead generates these samples using a state-of-the-art algorithm known as Hamiltonian Monte Carlo (HMC), which builds upon the Metropolis-Hastings algorithm by incorporating many theoretical ideas from physics. Actually, by default it implements a version of HMC called the [No-U-Turn Sampler](https://arxiv.org/pdf/1111.4246.pdf) (NUTS). It's easy to get bogged down in the conceptual complexity of these methods, so don't worry if you're not fully on-board at this stage; just internalise that we're generating samples stochastically, and accepting or rejecting those samples based on some probabilistic rule.\"\n",
    "\n",
    "[...]\n",
    "\"The first model we'll implement is\n",
    "\n",
    "$$y \\sim \\mathcal N\\left(\\alpha + \\beta X, \\sigma\\right),$$\n",
    "\n",
    "where we have an intercept $\\alpha$ and a gradient $\\beta$, and our data $y$ is distributed about this straight line with Gaussian noise of standard deviation $\\sigma$.\"\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
